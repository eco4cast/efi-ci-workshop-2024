[
  {
    "objectID": "workshopsummary/summary.html",
    "href": "workshopsummary/summary.html",
    "title": " EFI-CI Workshop Summary",
    "section": "",
    "text": "Jake Kritzer, Executive Director of NERACOOS, welcomed everyone and read a letter from Congressman Chris Pappas highlighting the importance of the workshop’s work on improving ecological forecasting systems. This is critical for preparing coastal New Hampshire communities like Portsmouth for impacts of climate change, including severe flooding from storm surges and sea level rise that have already caused millions in damage.\nMike Dietze, EFI Steering Committee Chair, provided an overview of the Ecological Forecasting Initiative (EFI). EFI formally launched in 2018 aiming to build an interdisciplinary community of practice around making ecological science more predictive and useful to society. It involves participants from academia, agencies, industry, and NGOs across disciplines like ecology, computer science, and social science. Key EFI activities include: - Hosting workshops, conferences, and sessions at major meetings - Organizing working groups on cross-cutting challenges like cyberinfrastructure, theory, decision support, education, and diversity - Education/training efforts like courses, webinars, and mentoring programs - Developing products like policy briefs and reports with agency partners - The ongoing NEON Forecast Challenge engaging over 32,000 forecasts so far - Community building through a Slack workspace, newsletters, and social media\nJake Zwart from USGS reviewed the specific background motivating this cyberinfrastructure workshop, tracing back to a 2016 meeting discussing the gap between ecological forecasting research funded by NSF and lack of operational implementations. The 2019 USGS report and 2020-2022 interagency roundtables identified cyberinfrastructure and stakeholder engagement as the biggest needs for transitioning forecasts to operations.\nThe main goals for this workshop are:\n\nDocument current CI practices across different forecasting projects\nIdentify common CI needs and gaps\nPropose a CI design to support various ecological forecasting applications\n\nThe primary outcome will be a living online “CI handbook” hosted on GitHub’s EFI organization synthesizing recommended practices. There is also potential for a future workshop on the research-to-operations gap.\nCameron Thompson discussed the process for developing the CI handbook by synthesizing input and findings from presentations, discussions, breakouts and documentation at this workshop. He reviewed the FAIR data principles (findable, accessible, interoperable, reusable) and introduced the CARE principles (collective benefit, authority to control, responsibility, ethics) which extend data governance considerations to indigenous data sovereignty. An interactive poll using PollEverywhere asked participants to define the boundary between “small” and “medium” size ecological forecasts to explore establishing a common vocabulary.\n\n\n\nSean Dorr and Melissa Kenney gave a joint presentation on applying design justice principles to improve the understandability and service equity of ecological forecasts.\nSean Dorr introduced himself as an Ojibwe tribal member and 4th year Computer Science PhD student at the University of Minnesota. His research focuses on incorporating indigenous perspectives into data visualization and human-computer interaction, bridging different worldviews.\nSean reviewed his work applying design justice principles with the Ecological Forecasting Initiative (EFI) community. Design justice centers people normally marginalized by design and uses collaborative creative practices to address community challenges. Key activities included:\n\nReviewing EFI projects against the 10 design justice principles to identify who is included/excluded\nPositionality exercise mapping education, geography, hobbies, skills, languages, career level, demographics, and values of participants\nCrafting engagements and paths forward to realize design justice with excluded communities\n\nEarly insights emphasized the importance of clearly defining “we,” “community,” and “designers,” identifying positionality, and applying the principles concretely.\nMelissa Kenney shared lessons learned from over a decade of research at the University of Minnesota to improve the understandability of environmental decision support products:\n\nVisualize the main story, nothing more\nSubjective feedback can be misleading\nEmpirical testing accelerates user-centered changes\nInteractive products require revisiting visualization norms\nEarly co-production with diverse users improves equity\n\nExamples included improving National Climate Assessment indicators, USGS water supply outlooks, NOAA temperature/precipitation outlooks, and drought monitors through redesign and controlled testing. She emphasized the power of empirical evaluation to drive research-to-operations improvements.\nMelissa also discussed an ongoing NOAA project to co-develop equitable flood and drought projections for the Upper Mississippi River basin by integrating climate models and engaging impacted communities. Building long-term relationships enables research questions and products to be transformed to better serve diverse users.\nIn the Q&A, they discussed strategies for expanding user testing as demands evolve and making the design justice approach scalable for resource-constrained agencies. Sean and Melissa welcomed follow-up discussions to provide feedback on specific visualizations.\n\n\n\n\nIn the Design Justice Principles activity session, participants worked in small groups to apply design justice principles to a specific goal: creating cyberinfrastructure that supports workflows for communities with limited Internet access. The activity had two parts:\n\nCrafting Engagements: Groups selected a relevant design justice principle and brainstormed ways to engage the community to achieve the goal, placing ideas on sticky notes along a spectrum from small to big effort.\nCrafting Paths Forward: Groups completed sentences to articulate how a selected engagement would lead to realizing the design justice principle, identifying metrics of success and envisioning long-term results.\n\n\n\n\nGroup 1: Focused on Principle 6 (everyone is an expert based on lived experience). They proposed finding boundary organizations to collaborate with the community, holding town halls with follow-up, and building shared resources. Success metrics included the percentage of community members using provided services. Long-term results envisioned a community forum to improve access.\nGroup 2: Selected Principle 10 (look for what’s already working at the community level). They suggested attending community events to understand current information flows and access. Knowing what information is used and how would enable developing a broader science communication toolkit tailored to community needs.\nGroup 3: Chose Principle 3 (prioritize design impact over designer intentions). They proposed engaging middle school students in and out of school to introduce data products, observe their interaction, and learn about community access needs. Students would share learnings with their families, expanding awareness.\nGroup 4: Also focused on Principle 3. With farmers as the community, they emphasized iterative feedback to prioritize design impact. Growing and retaining diverse feedback participants would indicate progress. Long-term results included having the feedback process adopted by others.\nGroup 5: Initially considered Principles 3 and 10 but settled on Principle 2 (center voices of those directly impacted). For rural and tribal college students with limited resources, they proposed iterative discussions to identify needed data products, test prototypes, and build community capacity to drive the process over time.\nGroup 6: Selected Principle 10 and some of 2. They suggested interviews/surveys to discover what already works and doesn’t work for Internet-limited communities. Identifying unexpected solutions and unrecognized problems would demonstrate progress. Long-term products should integrate with existing community practices.\nGroup 7: Emphasized Principle 3. They proposed collaborating via an on-site workshop to understand the design’s potential community impact. The community agreeing that the goals were communicated and the product was transformed would indicate success. Ongoing engagement and iteration were envisioned long-term.\n\nThe activity helped participants start orienting their thinking around design justice considerations even when working on cyberinfrastructure that may seem removed from people. The presenter emphasized that software always involves people—developers, users, collaborators—and encouraged the group to keep this human-centered lens throughout the workshop.\n\n\n\n\n\n\n\nIstem Fer, a senior researcher at the Finnish Meteorological Institute, presented on their work developing a cyberinfrastructure for agricultural carbon and greenhouse gas monitoring, modeling, and forecasting in Finland. Their goal is to quantify the impacts of regenerative agriculture practices and provide decision support to a range of stakeholders, with farmers as the primary end users.\nKey challenges they face include:\n\nThe need to work with multiple models, each with different operation input/output formats and programming languages\nThe models are heavily parameterized and data-intensive to configure, initialize, and calibrate\nThe workflows require advanced computing and complex automation\n\nTo address the challenges, they adopted an existing community cyberinfrastructure called PEcAn (Predictive Ecosystem Analyzer). PEcAn wraps around different process-based models, standardizing and automating the data flows and other tasks. Their typical workflow ingests a variety of field data, propagates uncertainty via model ensembles, performs calibration and data assimilation, and disseminates results via an online Field Observatory service.\nOne operational example is a 15-day iterative carbon flux forecast that assimilates data to adjust model states each day. However, most of their models are not yet compatible with formal data assimilation.\nTo improve scalability, they are in the process of migrating from traditional servers to a cloud-based Openshift cluster. Their wish list also includes enhancing the PEcAn API for 3rd party access, addressing model-data bottlenecks that hinder further scaling, providing more decision-relevant seasonal forecasts for farmers, and integrating with other EFI cyberinfrastructure such as forecast scoring standards.\nIn summary, the project is driven by stakeholder demand but still working on researcher adoption. PEcAn was chosen to enable the key need of multi-model interoperability. Openness, version control, modularity, and virtualization were important design elements. Despite the agricultural context, many aspects may serve as best practices for ecological forecasting cyberinfrastructure more broadly.\n\n\n\nDavid Watkins, a machine learning engineer with the USGS Water Mission Area, shared lessons learned from developing cyberinfrastructure for forecasting projects over the past few years, starting from a greenfield situation.\nHe emphasized thinking about the infrastructure in the broader context of batch vs. streaming data processing paradigms. USGS forecasting use cases like stream temperature, drought, and chlorophyll-a fall into the batch processing category, with forecasts running nightly to incorporate the previous day’s data.\nTheir initial stream temperature project had to prioritize speed and minimize new tools due to a short turnaround, leading them to incur technical debt. For the longer-term drought and temperature projects, priorities shifted to using a modern cloud-based approach for longevity, ease of maintenance via serverless services, and simplicity (e.g., repetitive daily processing vs. duplicating data stores).\nTheir current tech stack includes AWS Step Functions for orchestration, Docker for environment control, AWS Fargate/ECS, SageMaker, and S3 for compute and storage, GitLab for CI/CD pipelines, and CloudFormation for infrastructure-as-code.\nPatterns for success they’ve identified include:\n\nReproducible practices becoming non-negotiable\nModularity for debugging\nDiverse skills (software, modeling, visualization, outreach) in a cross-functional team\nPlanning for operations from the start\n\nTheir wish list includes more infrastructure staff, exploring ML-specific tools for experiment tracking, model registries, and feature stores, and increasing standardization across projects and organizations.\nIn the Q&A, David welcomed input on making this type of overview relevant for both machine learning and process-based modeling applications in the audience.\n\n\n\nClarissa Anderson from UC San Diego and the Southern California Coastal Ocean Observing System (SCCOOS) presented their work developing a prototype Harmful Algal Bloom (HAB) Data Assembly Center as part of the U.S. National HAB Observing Network (NHABON).\nThe HAB problem in California is primarily due to the diatom Pseudo-nitzschia and the neurotoxin domoic acid it produces, which has impacted fisheries, marine mammals, and public health. While there is a long history of HAB monitoring and modeling in California, the Imaging FlowCytobot (IFCB) network provides a new opportunity for near real-time, high-resolution observation of phytoplankton communities.\nWith funding from the NOAA NCCOS HAB Community Technology Accelerator project, they are developing the HAB Data Assembly Center to provide centralized cyberinfrastructure for the IFCB network.\nKey elements include:\n\nAutomated data accession, image processing, and product generation\nClassifier training, evaluation, and application tools\nStandardized community annotation workflows\nOpen source best practices for software, methods, and metadata\n\nThe Transition Advisory Committee helps identify barriers and broaden the scope beyond California. Priorities include extending to other regions, engaging diverse stakeholders, and finding a sustainable home for the system.\nDownstream applications have included a daily alert system for managers, morphometric trait databases for ecosystem modelers, and transformations to push data to repositories like OBIS.\nTheir wish list includes plug-and-play instrument integration, expanded regional nodes, more management-tailored products, and an instrument-agnostic evolution into a general Plankton Data Assembly Center with community-wide standards for imagery data.\n\n\n\n\nCarl Boettiger started with principles for designing cyberinfrastructure to make it easier to integrate the explosion of ecological data and forecasting methods. Key points included:\n\nThe “Lego principle” - components should be modular, reusable, and interoperable based on common standards without custom modifications that break compatibility\nAgreement on standards is critical - e.g., common table formats for forecasts\nUse of reproducible compute environments (e.g., Docker), S3 object storage, and range requests for efficient data access\n\nQuinn Thomas then shared stories of applying these principles in the NEON Ecological Forecasting Challenge, a platform that enables the ecological forecasting community to submit iterative near-term forecasts of NEON data before it is collected. Their journey included:\n\nTraining the community via workshops and template repositories\nAutomating daily forecast submission and evaluation using modular CI components\nScaling up from hundreds to thousands of forecasts per month by shifting to self-hosted runners\nExtending the platform to partner projects like LTER and USGS via a “forkable CI”\nDeveloping a clearinghouse of challenge catalogs to make grassroots efforts discoverable\n\nThroughout, adherence to common data and metadata standards allowed flexibility to adapt to growing scale and scope.\nTheir wish list includes further sharing of “Lego brick” components, increased multi-language support, and deeper engagement with the machine learning community.\nOverall, the presentation highlighted how careful CI design around modularity and standards from the beginning enables a community of forecasters to build and innovate together.\n\n\n\nRenato Figueiredo from the University of Florida (soon Oregon State University) presented work done in collaboration with Cayelan Carey and Quinn Thomas from Virginia Tech on extending their FLARE (Forecasting Lake and Reservoir Ecosystems) cyberinfrastructure to a more generalizable system called FaaSr.\nFLARE uses a cloud-based event-driven workflow leveraging Docker containers for reproducibility and Function-as-a-Service (FaaS) for serverless invocation of the containers. Intermediate data is stored in S3 buckets. The key goals were scalability, reproducibility, and low barriers to entry for development and deployment using R.\nWhile FLARE addressed specific project demands, FaaSr aims to generalize the approach to support:\n\nMultiple cloud FaaS providers without code changes\nComposition, sharing, and reuse of workflows\nDecoupling of workflow configuration from code\n\nFaaSr is an open-source R package that simplifies development and deployment of FaaS workflows. Users write functions in R, use S3 for data I/O, and describe the workflow composition in a JSON configuration. FaaSr automates the registration, execution, and orchestration of the workflow on different FaaS platforms (GitHub Actions, OpenWhisk, AWS Lambda).\nKey features include cross-platform support via Docker and S3, a GUI for visual workflow composition, and flexibility to use custom containers per function. Figueiredo demonstrated a NEON forecast example running with minimal code changes and a proof-of-concept for concurrent execution across platforms.\nThe wish list includes community resources like shared S3 buckets and OpenWhisk instances, improved usability through GUIs and cloud training, and community engagement for feedback, new features, and workflow sharing.\nFigueiredo expressed enthusiasm for collaborating with the ecological forecasting community and contributing to initiatives where possible.\n\n\n\nAlexandra Kirk, a cloud engineer at Development Seed, presented on behalf of the NASA IMPACT (Inter-agency Implementation and Advanced Concepts Team) on VEDA, an open platform that brings Earth science datasets to open-source tools for data processing and analysis.\nVEDA was initiated in response to the need for inter-agency collaboration and data sharing during COVID lockdowns when on-premise resources were unavailable. It has since evolved to reduce barriers to compute resources, data publishing, and sharing insights with both technical and non-technical audiences.\nKey elements of VEDA’s cyberinfrastructure include:\n\nOpen source Earth Observation API (EO-API) tools for bootstrapping a “stack catalog” with APIs and tiling resources for efficient data access\nModular components that enable multiple teams to assemble customized “VEDA stacks”\nContinuous development and improvement driven by community usage\n\nThe core workflow involves:\n\nTransforming data to analysis-ready cloud-optimized (ARCO) formats in S3 storage\nDeploying cloud compute resources (e.g., Jupyter Hubs) co-located with the data for efficient processing\nSharing data and insights back out via APIs, web applications, and dashboards\n\nThe EO-API infrastructure includes a PostgreSQL database with a STAC schema, a FastAPI service conforming to the STAC specification, and libraries for querying data by space, time, and properties.\nAn example of VEDA in action was scaling an algorithm developed by the NASA EIS Fire Tracking team from California to near real-time coverage of the Continental US. This involved integrating with the MAAP processing system, scheduling jobs, and publishing outputs to the VEDA API for dashboard visualization.\nKirk emphasized the importance of VEDA’s open modular design in enabling collaboration and continuous improvement through community usage. Documentation, tutorials, and a JupyterHub for hands-on exploration are available at the shared links.\n\n\n\n\nHassan asked where PEcAn gets its data from. Istem and others responded that it primarily uses public APIs.\nA question was posed about how NEON uses Docker. The response was that most researchers already have a local workflow and wouldn’t want to change it, so ideally the Docker usage is invisible and just works. However, power users would know what to do with Docker themselves.\nHassan inquired about reporting AI-generated data, including QA/QC. Clarissa explained that uncertainty metrics come out of the analysis, and while the ML process is an identification process, the data is real, not synthetic (though it may become interpolated). David added that the outputs aren’t particularly special, but the difference is in provenance tracking, which needs a specific identifier for things like training data.\nThere was a discussion about Open Geospatial Consortium standards. Carl mentioned that there is some tension and complexity in the evolution of standards through the OGC model versus the open-source community model.\nJake Zwart noted that Istem seemed to be the only one using an existing CI or workflow and asked others about their decision processes for adopting or developing workflows. Istem explained that she helped develop PEcAn, which solved problems similar to what she was working on. While it’s been difficult to get external groups to adopt it, it’s now more distributed, with mostly agricultural groups using it. Renato pointed out that a challenge with workflows is the infrastructure behind them, and moving to the cloud helps avoid infrastructure upkeep and lock-in.\nA question was raised about the risk of vendor lock-in when using cloud services. David responded that they use services in a fairly generic way, so while there would be some costs, they could migrate to another commercial cloud provider if needed. Renato added that moving to the cloud model already makes it easier to transition between platforms. Carl mentioned that they’ve already had experience with this issue.\nIstem asked how NEON and other challenges talk to each other. Quinn and Carl explained that they are linked at the catalog level, so a search for something like chlorophyll-a forecasts in Wisconsin could return results from different challenges. They also share fundamental packages and Docker containers. EFI made a strategic decision to keep the challenges separate to empower communities and maintain data sovereignty rather than forcing everything to go through EFI, which acts more as a clearinghouse for standards and components.\n\n\n\n\n\n\nBased on a comprehensive review of the breakout session notes, report-outs, and the broader context provided by the workshop presentations, several key themes, tensions, and challenges emerged regarding the current state and future development of ecological forecasting workflows.\n\n\nA dominant theme across all breakout groups was the crucial role of standards and best practices in enabling the development of robust, interoperable, and sustainable ecological forecasting workflows. There was also broad agreement on the need to “develop by using standard practices in other fields rather than reinventing them.” Groups emphasized the value of adopting and adapting existing standards and practices from fields such as software development, data management, and cloud computing. They discussed the importance of establishing community-wide conventions around data formats, metadata schemas, and workflow design patterns to facilitate collaboration, reproducibility, and scalability. Nevertheless, participants also recognized the challenge of balancing standardization with flexibility and adaptability. This tension between top-down standardization and bottom-up customization was a recurring theme, particularly in discussions around the differing needs of research and operational workflows.\n\n\n\nAnother major theme was the challenge of integrating and harmonizing heterogeneous data from diverse sources and formats. Participants highlighted this as a key bottleneck in ecological forecasting workflows, noting that “biological and ecological data is very hard to standardize.” As one group put it, “we thought that some physical data can be standardized… but it is challenging for biological and ecological data.” Furthermore, there was some disagreement about the feasibility and desirability of completely standardizing all ecological data types. Groups discussed the need for better tools, methods, and conventions to support data cleaning, transformation, integration, and provenance tracking. They also emphasized the importance of capturing and propagating uncertainty throughout the data lifecycle. Some participants suggested a more pragmatic approach with “even if not community-wide standard, a project standard will be useful.”\n\n\n\nCutting across many of the breakout discussions was a recognition of the vital importance of effective communication, collaboration, and cultural practices in advancing ecological forecasting workflows. As one group put it, ecological forecasting as a community and field was reaching a critical mass due to greater technology and data access, which enables rapid development and opportunity but also presents challenges. Participants repeatedly emphasized the need for closer collaboration and better communication between domain scientists, IT experts, and other key stakeholders.\nAs one group noted, IT experts may not address the right questions through their forecasting CI design, while a domain scientist may code a fragile system; thus, there needs to be intense communication between them. Likewise, another group called for engineer and scientist mutualism and synergy without siloing. Groups also discussed the importance of fostering a culture of openness, transparency, and continuous learning within the ecological forecasting community. They highlighted the need for better documentation, knowledge sharing, and training resources to support the adoption and long-term maintenance of best practices. However, participants also acknowledged the challenge of overcoming entrenched organizational and disciplinary silos, as well as the lack of incentives and rewards for investing in these kinds of activities. As one group put it, “a lot of these best practices really boiled down to software development best practices,” but “it was very important to also make sure to understand and articulate the motivation for the forecasting.”\n\n\n\nMany groups discussed the potential of cloud computing and modular, interoperable architectures to accelerate the development and deployment of ecological forecasting workflows. Participants highlighted the benefits of technologies such as containers, object storage, and serverless computing in enabling reproducibility, scalability, and flexibility. They also emphasized the value of breaking down complex workflows into smaller, reusable components that can be shared and recombined in different contexts.\nHowever, some groups also raised concerns about the potential risks and trade-offs associated with a wholesale move to the cloud, particularly around issues of vendor lock-in, long-term sustainability, and data sovereignty. Participants grappled with how to balance the benefits of leveraging industry tools and platforms with the need to retain control and ownership over critical infrastructure and data assets. As one participant put it, “Commercial providers are now subsuming some things that might have been viewed as having government roles but without the social contract that they do when they’re in government.”\n\n\n\nA recurring tension throughout the breakout discussions was the challenge of reconciling the differing needs, incentives, and constraints of research and operational environments. Groups highlighted the tension between research quality and production quality workflow, noting that each requires a different set of skills, tools, and practices. Participants discussed the difficulty of translating research models and workflows into production-ready systems, as well as the lack of communication and coordination between research and operational teams.\nSome groups emphasized the need for greater investment in the “human factors” and organizational aspects of ecological forecasting, such as training, documentation, and stakeholder engagement. They argued that “technology has reduced some barriers but more work is needed” and that “the people that we need aren’t necessarily engaged.” Participants also noted the tension between the scientific incentives for novelty and innovation and the operational requirements for stability, reliability, and continuity. As one group put it, “scientists and the systems they are in value innovation over stability, but what’s really needed is stability, which is not well-valued.”\n\n\n\nWhile not all groups engaged deeply with the design justice principles presented earlier in the workshop, there was a general recognition of the need to center equity, inclusion, and participation in the development of ecological forecasting workflows. Some participants highlighted the potential of cloud-based workflows to enable greater access and democratization, noting that “data in the cloud enable capacity development” and that “you don’t have to do the forecast on your own device.” Others emphasized the importance of engaging diverse stakeholders throughout the workflow lifecycle, from problem formulation through to the dissemination and use of forecasts. However, groups also acknowledged the significant challenges, noting that “access is probably the biggest issue right now” and that “some communities simply don’t have the wherewithal to even start looking.” They discussed the need for more intentional and proactive outreach to underrepresented groups, as well as the importance of designing workflows that are accessible and responsive to the needs and constraints of diverse users. Some groups also highlighted the challenges of ensuring transparency and accountability in the use of ecological forecasting workflows, particularly when working with aggregated or derived data products.\n\n\n\n\n\n\n\n\n\n\nThe biggest bottleneck is human capital and the steep learning curve required to operationalize a forecast. Shared tools and infrastructure are needed to flatten this curve.\nThe high cost (~$5M per forecast according to NASA) and learning curve create barriers to entry and major equity issues as it limits forecasts to data-rich systems and affluent countries rather than underserved communities that may need the information most.\nThe result is many individual “boutique” forecasting systems that don’t share code or methods. Community cyberinfrastructure is needed to share costs, avoid reinventing wheels, and make forecasts more interoperable and reusable.\nKey priorities for shared infrastructure include: standards/interoperability, scalable data ingest, automation tools, archiving and findability of forecasts and data, and assimilation/hybrid modeling methods.\nMost ecological forecasts are a “medium” scale - too big for manual methods but not big enough for dedicated infrastructure like the weather enterprise. Shared tools are essential for this scale.\nHowever, data volumes are rapidly increasing to petabyte scales, so some ecological forecasts may reach weather-like big data challenges soon.\nSustainability of shared infrastructure funding is a major unresolved challenge.\nCultural barriers include the “if you build it they will come” fallacy - community building and buy-in is essential, not just tool development.\nAcademics tend to get stuck in funding “ruts” and have difficulty branching out to other funding sources and partnerships.\nCoproduction with users is essential but very difficult in practice, especially for early-career researchers. Alternative partnership models are needed.\nOvercoming barriers requires fiscal and cultural buy-in as well as more training to flatten the learning curve.\n\n\n\n\n\nMarie has a background in physical oceanography and has worked at NASA, Navy, and NOAA. She advocates for building a forecasting culture to help people see and prepare for the future.\nThe vision is a National and International Ecological Forecasting Enterprise. Key questions include who it’s for, at what scale and impact, who operates the forecasts, and how to standardize curricula.\nIn 2014, the American Meteorological Society (AMS) Committee on Ecological Forecasting was established. Over the last 4 years as chair, Marie worked to get the AMS to endorse a formal statement on the future of ecological forecasting to organize and focus policy and funding. The statement was approved in January 2024. AMS Statement\nEcological forecasts need to identify relevant time and space scales. Marie showed examples linking standard weather service products to ecological phenomena that would need forecasts.\nEnvironmental security is a key driver - e.g., sinking islands displacing people. Forecasts need to incorporate economic and social equity dimensions.\nForecasts should start by identifying the decision/action needed as close to the decision point as possible. Environmental intelligence should synthesize data, science, management, and knowledge to meet stakeholder needs.\nMarie highlighted efforts like the NEON forecasting challenge and USGS HAB challenge as examples of research efforts that generate innovations that can eventually transition to operations.\nThe weather enterprise has doubled forecast skill in 15 years through consistent funding and systematic approaches. Marie advocates for leveraging existing operational infrastructure where possible for efficiency.\nMarie highlighted how the roles of the private sector have changed dramatically since 2003. Industry is now an instrument builder, data provider, model developer, and distributor of products. Cloud services are replacing government infrastructure. The workforce is Internet native.\nThe top industries for data scientists don’t explicitly include environment, but environment factors into all of them. Ecological forecasters can make connections and bring methodologies to the weather/climate modeling community.\nCyberinfrastructure needs include: compute power, data storage and I/O, federated systems, access frameworks, workflow tools, development environments, interactivity, and standards.\nNext steps include identifying stakeholders, consolidating needs, integrating forecasting across agencies, conducting workshops, categorizing products, defining platforms, quantifying infrastructure needs, developing governance structures, and focusing funding.\n\n\n\n\n\nDavid is the NOAA ecological forecasting portfolio manager. His talk covered NOAA’s ecological forecasting framework, progress on a national HAB forecasting system, and implications for cyberinfrastructure.\nNOAA’s ecological forecasting efforts build on its history in forecasting and leverage existing operational models and data where possible. Current focus areas are harmful algal blooms (HABs), hypoxia, pathogens, and living marine resources.\nDavid provided examples of operational forecast products for each focus area, highlighting the benefits, stakeholders, and components that go into each:\n\nGulf of Mexico HAB Forecast - predicts respiratory irritation risk, bloom location/extent\nChesapeake Bay Vibrio Forecast - predicts concentrations in oysters to guide shellfish harvesting\nLake Erie Hypoxia Forecast - predicts low oxygen events to aid drinking water management\nPuerto Rico Habitat Assessment - predicts fish biodiversity hotspots to inform spatial planning\n\nFoundational capabilities that support ecological forecasts include NOAA’s suite of operational forecast systems for the physical environment and extensive observing systems (satellites, in-situ monitoring).\nCollaborations and partnerships are essential, e.g., the Pacific Northwest HAB Bulletin involves coordination across a dozen federal, state, tribal, university, and nonprofit entities.\nNOAA has established a vision and requirements for a National HAB Forecasting System that weaves together regional systems into an operational framework. Key elements include co-development with stakeholders, transition plans, and research to improve operational capabilities.\nDavid walked through an example system anatomy and workflow for the Gulf of Maine HAB Forecast, highlighting areas of automation vs manual steps. Cyberinfrastructure improvements include documentation, automation, standardization, integration, and research-to-operations pathways.\nMajor technical gaps include standardization across regions, integration of multiple data streams, coupling with physical models, and stable computational resources for real-time vs scenario forecasts.\nCultural barriers include inconsistent nomenclature and expectations between research and operational groups.\nChallenges working across organizations include misalignment of mission needs affecting data sharing and extensive dependencies that create vulnerabilities.\nRecommendations include utilizing national frameworks tailored for regions, fostering the next generation of forecasters, and learning from ongoing efforts to consolidate operational systems.\n\n\n\n\n\nQuinn asked about the receptivity of agencies to adopt shared tools and approaches developed by the academic community. David said NOAA is moving toward more open-source frameworks but there are still constraints. Marie noted that transitions are costly and nonlinear so the most mature approaches should be prioritized through intercomparison projects. Unexpected funding opportunities can also accelerate progress.\nMike asked about the modularity and accessibility of NOAA’s Unified Forecast System for ecology. David said it depends on the topic - atmospheric and coastal modeling is further ahead but there is intent to incorporate ecological components, though fine scale resolution is a challenge. Marie highlighted the need to actually connect with HPC/modeling groups who have placeholders for ecological components but may not know how to implement them. Mission conflicts can also arise between physical and ecological model requirements.\nCarl asked about the role of incentives and funding structures in perpetuating barriers. Marie described how government performance metrics flow down to shape individual incentives. Strategic planning across agencies and program managers is needed to build more coordinated initiatives. Following the money flow reveals actual priorities.\n\n\n\n\n\n\n\n\n\nChris is a principal software engineer at Red Hat Research who started working with Dr. Mike Dietze on the PEcAn project in January 2023 to develop an asynchronous distributed cloud-native workflow for PEcAn.\nEcological forecasting researchers need open-source, accessible, reusable, and scalable software tools. PEcAn previously ran on high-performance computers which were not very accessible or scalable compared to the cloud.\nThe ecological forecasting team consisted of Boston University software engineers, graduate students, Professor Dietze, and Chris as the Red Hat software engineer. The Red Hat Collaboratory with BU is a partnership advancing research in emerging technologies.\nIn 2023, they prototyped an accessible community infrastructure to generate ecological forecasts at scale, focusing on an asynchronous, event-driven, distributed cloud-native workflow.\nThey deployed PEcAn on the New England Research Cloud (a shared cloud environment across several universities) using Kubernetes, PostgreSQL, RabbitMQ, and Jupyter notebooks. This allowed students and engineers to share the same cloud environment.\nKey open cloud solutions included open-source branching, distributed storage, pod auto-scaling based on messages, and an rsync strategy for transferring forecast data.\nRed Hat OpenShift provides an open-source, accessible, reusable, and scalable cloud platform for ecological forecasting from laptops to data centers. Chris demonstrated running PEcAn on his laptop using OpenShift.\nFuture milestones include an asynchronous event-driven scheduler, elastically launching data ingest containers, and supporting more sites/data/models. Successful collaborations involve subject matter experts, grad students, software engineers, and cloud computing resources.\n\n\n\n\n\nJake Zwart asked why Chris is enthusiastic about ecological forecasting. Chris said he enjoys helping communities with great ideas implement the enabling technologies, especially open web initiatives.\nHassan asked about APIs and interoperability in PEcAn. Mike Dietze listed several data sources ingested (e.g., NASA MODIS, flux net carbon, NEON data, etc).\nHassan asked about human capital, i.e., how many people are working on this. Mike answered that the PEcAn project has been around for 15 years and has had 84 pull requests; there are about 12 core developers, fluctuating based on funding.\nMike answering Hassan: Sustainability is difficult due to the ebb and flow of grants. PEcAn gets funding mostly through science-driven projects that also support infrastructure development rather than dedicated grants for the cyberinfrastructure alone. It’s an example of the problem of innovation being valued over sustainability in the funding environment.\nMike answering Hassan: Interoperability challenges arise from conflicts between modularity and provenance tracking that relied on a monolithic database.\n\n\n\n\n\nKelly is the data management lead for MARACOOS and Executive Director of RPS Ocean Science. She presented on the data management and cyberinfrastructure efforts of the U.S. Integrated Ocean Observing System (IOOS) and their transition to the cloud.\nIOOS brings together thousands of ocean observing datasets daily to support maritime safety, coastal resilience, ecosystem health, etc. The DMAC (data management and cyberinfrastructure) subsystem ensures the data is acquired, stored, quality-controlled, discoverable, accessible, and usable.\n\nUsability previously meant download but increasingly means Cloud compute via Jupyter notebooks.\n\nIOOS DMAC is transitioning to the cloud for improved scalability, continuity, cost-effectiveness, and alignment with NOAA’s cloud migration. However, it’s mostly been a “lift and shift” so far without optimizing for cloud-native architectures.\nThe “Reaching for the Cloud” project aimed to reduce barriers for data providers and users by developing a roadmap and cloud-native prototype solutions, especially for working with model data.\nIOOS RAs are challenged by working with forecast model outputs in Thredds.\nKey solutions included using Kerchunk and Zarr for cloud-optimized data representation, XPUBLISH for data access APIs, and automated event-driven workflows triggered by new data arriving in cloud storage.\nCase studies showed massive performance improvements for analyzing the 40-year Coastal Ocean Reanalysis dataset and the National Water Model using these cloud-native solutions.\nIOOS also developed a ‘coastal modeling cloud sandbox’ to enable collaborative development and efficient research-to-operations transitions. It provides a shared cloud environment with model code, input data, and HPC for testing.\nNext steps include expanding the sandbox for NOAA partners, archiving outputs to the cloud, and integrating with other IOOS cloud efforts. Getting NOAA buy-in leveraged existing relationships between the agency and cloud providers.\n\n\n\n\n\nRich asked if they had to iterate on chunk sizes when moving to the cloud. Kelly said yes, they experimented to find a balance between optimizing for time series extraction vs. whole-grid mapping.\nCarl asked how they got NOAA to agree to the cloud migration. Kelly said NOAA was already engaging with cloud providers for research partnerships, so IOOS leveraged those existing relationships which made cloud resources accessible. The transition felt organic as internal groups like CO-OPS were also naturally moving to the cloud.\n\n\n\n\n\n\n\n\n\nEcological forecasting encompasses a wide range of applications and domains of knowledge, each with unique requirements.\nForecasts vary in scales, requiring cyberinfrastructure that can accommodate this range.\nIdentifying commonalities while allowing for customization is a key challenge.\nGroup 1 proposed “validating the hypothesis that there are a manageable number of basic workflows that apply to all ecological forecasting tasks” as a starting point for identifying commonalities.\n\n\n\n\n\nAll groups discussed the role of standards in facilitating interoperability and reuse. However, they acknowledged that strict standards can limit flexibility and adoption.\nGroup 1 suggested standards should transcend specific formats and focus more on standardizing outputs than inputs. Group 4 proposed aiming for “common concepts for describing data” rather than rigid specifications.\nFocusing on standardizing outputs rather than inputs and borrowing conventions from other domains could help.\nCommunities of practice resist top-down standardization efforts that don’t include their input.\n\n\n\n\n\nGroups frequently mentioned the steep learning curve for existing forecasting tools and the overall difficulty of operationalizing a forecast as major challenges, particularly for less resourced organizations.\nStanding up a forecast requires not only domain knowledge but also data science, software engineering, and DevOps skills that are not traditionally part of ecology curricula. The field needs more dedicated research software engineers and data scientists.\nBetter documentation, code carpentry, and accessible training programs could help expand the pipeline and make forecasting more welcoming to inexperienced groups.\n\n\n\n\n\nLack of sustained funding makes it difficult to maintain forecasting cyber infrastructure long-term.\nGrant-funded academics struggle to operationalize and maintain systems once papers are published and money runs out. Even large agencies like NOAA struggle with continuity.\nGroups proposed a variety of approaches to pooling resources and advocating for investment. Grassroots efforts are valuable for building community but likely not sufficient.\n\n\n\n\n\nSocial and cultural barriers, not just technical ones, impede adoption of new forecasting approaches.\nRigid organizational requirements around security and procurement limit options for innovation.\nWorkers are “stuck in ruts” and habituated to familiar technologies and workflows. Switching to new shared systems means giving up some control and recognition which is not typically rewarded.\nInteroperability requires give and take between collaborators, but often organizations define their own conventions to meet immediate needs and maintain ownership. “Not invented here” mindset prevails.\n\n\n\n\n\nForecasts need to be designed with users’ decisions in mind, not just advancing science.\nThe groups agreed that stakeholder engagement is critical to designing relevant and usable forecasting products. However, cultivating those relationships is undervalued and takes substantial time and energy that is not always budgeted in research grants.\nAs group 3 pointed out, many current ecological forecasts are not actually designed to inform specific decisions. Connecting products to actions requires dialogue and trust-building that does not happen overnight.\nHigh-quality engagement is especially difficult with under-resourced and marginalized communities. A vicious cycle ensues where those most in need of information are least engaged in the process.\n\n\n\n\n\n\n\n\nDevelop community standards for model metadata, data formats, workflows, APIs, but adopt existing standards where available.\n\nSome groups further proposed focusing on standardizing concepts, not just variables and formats, to provide a more flexible foundation.\nIt was further noted that modular, loosely-coupled architecture can help minimize dependencies and allow for evolution of standards over time.\n\nIncentivizing the use of standards through funding requirements, community recognition, and demonstrated value for stakeholders could accelerate adoption.\n\n\n\n\n\nAll groups recognized that the success of cyberinfrastructure efforts depends on having people with the skills to develop, operate, and apply it effectively. Ecological forecasting requires a distinctive blend of domain knowledge, data science, statistics, and software engineering that is not adequately addressed.\nGroups called for a mix of strategies including developing a “skills pipeline” for students, enlisting professionals from the tech industry to contribute their expertise, and embedding “research software engineers and data scientists” within ecological forecasting teams rather than relying on domain scientists to develop technical capacities on top of their other responsibilities.\nProviding accessible, inclusive, and culturally-relevant training for diverse communities was seen as essential for broadening participation and ensuring the ethical development and application of forecasts.\n\n\n\n\n\nEngaging communities and stakeholders early and iteratively was identified as critical for ensuring that forecasting products are actually useful and used. Participants recognized that model development often happens in isolation from the communities it is intended to serve.\nGroup 1 called for “iteration between forecast producers and users” to refine products over time. They highlighted the need for “boundary organizations” to help translate needs and feedback across domains.\nGroup 3 posited that we should “build communities before we build tools” to center the user experience from the start. They suggested that human-centered design and design justice should be guiding principles for the community.\nGroup 5 noted that stakeholder engagement “requires dedicated time and funding” that is often not accounted for in current grant structures. Sustaining long-term collaborations requires shifts in the incentive structures of academia and agencies.\n\n\n\n\n\nParticipants recognized that a lack of discoverability and accessibility of existing models, data, and tools was a major barrier to efficient forecasting workflows. While valuable resources exist across the community, they are often siloed within particular organizations or projects. Recommendations for overcoming this barrier include:\n\nEstablishing a community catalog/archive for models, data, and tools\nIncorporating sample datasets and containerized environments in model archives\nEnabling cloud-based access to data from existing repositories\nShowcasing and rewarding examples of effective reuse of forecasts and tools\n\n\n\n\n\n\nAcross all groups, there was a recognition that cyberinfrastructure needs to be able to accommodate the diverse scales and applications of ecological forecasting and that a monolithic one-size-fits-all solution is unlikely to meet the community’s varied needs. Therefore, the groups suggested:\n\nFocusing on modular, loosely-coupled components that can be recombined in different ways for different use cases. Having well-defined interfaces between components can then enable adaptation for different needs.\nUtilizing cloud platforms for scalability while maintaining the ability to run locally\nSupporting multiple access modes (GUI, API, Jupyter notebooks) for different user groups\n\n\n\n\n\n\nDeveloping tools and platforms using open source software and development practices was seen as essential for building a collaborative, inclusive, and sustainable ecological forecasting community.\nProprietary tools and platforms can create barriers to entry and hinder interoperability.\nMeanwhile, open source approaches can enable faster progress by allowing the community to build on each other’s work and catch errors more quickly.\nTransparency and the ability to audit code will also build trust in forecasting methodologies and results.\nInvesting in the sustainability and maintenance of key open source tools and libraries that support forecasting, such as PEcAn, was seen as a high priority for funders.\nWhile open source was strongly advocated, participants also acknowledged the need to provide stable, supported platforms for operational forecasts which may require more formalized approaches.\n\n\n\n\n\nSecuring sustainable funding and establishing long-term partnerships across sectors was recognized as one of the most critical and challenging aspects of advancing ecological forecasting cyberinfrastructure.\nA number of strategies were suggested by groups to overcome this obstacle:\n\nEstablish long-term and diverse funding streams through cooperative agreements or public-private partnerships\nQuantify and communicate value of forecasts to stakeholders to encourage investment\nExplore cost-sharing approaches like in-kind computing contributions\n\nPartnerships and funding could then support:\n\nA dedicated “National Ecological Forecasting Center” that could serve as a hub for both research and operations.\nForecasting challenges with prizes\nCommunity-directed funding pools\n\n\n\n\n\n\nEmbedding design justice principles into the development of ecological forecasting cyberinfrastructure was lifted up as a priority, with groups observing that:\n\nEcological forecasting needs to partner with and center underrepresented communities in the design process, not just engage them as an afterthought.\nData colonialism has perpetuated harm, and indigenous data sovereignty needs to be respected.\nCultural relevance and accessibility should be considerations when evaluating proposals.\nCommunity partners need to be compensated for their time and expertise, and we shouldn’t just extract knowledge.\nPartnering with grassroots organizations, citizen science initiatives, and community-based monitoring networks was valuable\n\n\n\n\n\n\n\nWho do you consider to be the “we” as the designers of ecological forecasting CI?\n\nPractitioners actively developing forecasts and CI tools (Group 3)\nTechnologists and researchers involved in EFI from various sectors (Group 5)\nManagers setting strategy and advocating for resources (Group 1)\n\nWho do you consider to be the “community” we’re designing ecological forecasting CI for or with?\n\nForecast producers across agencies, academia, industry, NGOs (Group 1, 3)\nStakeholders and end users who will apply the forecasts (Group 1, 3)\nGeneral public, taxpayers, and communities impacted by forecast outcomes (Group 3)\nPotential future users and research community at large (Group 3)\n\nWho might be excluded in your list of design principles for ecological forecasting CI?\n\nTribal, indigenous, and underrepresented communities (Group 3, 4)\nGroups not present in the design process to advocate their needs (Group 3, 5)\nLess-resourced organizations unable to meet technical/data requirements (Group 1)\nThose uncomfortable with proposed technologies or resistant to change (Group 5)\n\nAre there ways to include these people with different design choices?\n\nProactively co-develop with marginalized groups from the start (Group 3, 4)\nEnsure broad representation of stakeholders in the design stage (Group 1)\nProvide accessible training and support for underserved groups (Group 3)\nMake tools modular and interoperable to reduce barriers to participation (Group 1)\n\n\n\n\n\n\n\n\nAdvocated for reactivating interagency activities with an ecological focus, serving as a clearinghouse.\nNoted that COVID impacted public-private partnerships and the need to re-engage.\nEmphasized the difficulty of writing contract deliverable proposals for the private sector and suggested agencies reconsider their RFP processes.\nStressed the importance of balancing the three pillars: public, private, and academic sectors.\n\n\n\n\n\nArgued that on-premise systems are coming to an end and transitioning to the cloud is inevitable.\nEmphasized the need for standardization to leverage resources effectively.\nSuggested that the community should develop standards and expand adoption until hitting a tipping point at which point agencies can be pushed to accept them.\nNoted that providing data in formats used by the forecasting community could save agencies money on grants.\n\n\n\n\n\nHighlighted that even within NOAA, there are cultural differences and collaboration barriers between line offices.\nSuggested that demonstrating successful cross-agency projects like the multi-stressor project could pave the way for more interagency funding opportunities.\nNoted that incentives for collaboration need to come from the top.\n\n\n\n\n\nShared examples of successful interagency coordination like the Civil Earth Observations initiative.\nNoted that the shift to cloud computing has broken traditional architectures because it changes how users interact with data.\nArgued that agencies are no longer driving technology development and are beholden to commercial cloud providers, leading to a loss of control.\nStressed that agencies need to collectively define their requirements for cloud services rather than just accepting what vendors offer. This could help provide market certainty for vendors while ensuring agency needs are met.\n\n\n\n\n\nProvided the multi-stressor project as an example of successful cross-agency collaboration within NOAA but noted it takes a lot of effort.\nSuggested updating policy documents to explicitly address interagency ecological forecasting needs.\nNoted that existing interagency agreements (IAAs) tend to be very topic-specific.\nProposed engaging with Congress to direct agencies to work together on ecological forecasting but since federal employees cannot lobby, this would have to be proposed by the EFI community.\n\n\n\n\n\nShared experiences working across multiple agencies as a contractor and noted that successful interagency collaborations exist but tend to be inflexible.\nEmphasized the importance of having project champions and executive sponsors to drive things forward while noting the challenges of finding people with the bandwidth to take on that role.\nHighlighted the importance of community building and the difficulty of coordination as initiatives grow beyond 100-150 people.\nWarned against the tendency for collaborative infrastructure efforts to try to meet everyone’s needs but end up serving no one well - “beware the monolith.”\n\n\n\n\n\n\nChris Brown asked Clarissa Anderson and David Scheurer about how to break down barriers between NOAA line offices. Clarissa suggested that incentives need to come from the top.\nMarie Colton proposed the idea of a “Fairweather Report” for ecological forecasting to engage different stakeholders and drive Congressional action.\nTyson Swetnam from the audience commented on the high costs of using commercial cloud services, particularly for academic research, and the importance of finding ways to manage egress charges.\n\n\n\n\n\nInteragency Collaboration: All panelists agreed that interagency collaboration is critical for advancing ecological forecasting CI but significant organizational, cultural, and technical barriers remain. However, there have been examples in the past of successful interagency initiatives. Top-down policy mandates, cross-agency demonstrator projects, and bottom-up community efforts were all seen as important mechanisms for driving progress.\nCloud Computing Disruption: The rapid and inevitable shift to cloud computing is upending traditional IT architectures, procurement models, and budget structures. As a result, agencies are spending more on operating costs and losing leverage to commercial providers. Coordinating requirements across agencies and presenting a unified front to vendors was seen as a potential solution to some of the challenges.\nImportance of Standards: Developing community-driven standards is essential for enabling interoperability, efficiency, and collaboration across disparate projects and organizations. Encouraging standards to emerge from the EFI community and reach a critical mass of adoption before being codified into agency policy was suggested as a strategy. Although standardization is important, panelists cautioned against over-specifying solutions or building monolithic systems that try to be everything to everyone. Cyberinfrastructure should remain modular, loosely coupled, and adaptable to the needs of different use cases. Finding the right balance is an ongoing challenge.\nSustainable Funding: Securing long-term stable funding for collaborative infrastructure projects is a major challenge. Panelists highlighted the importance of exploring creative funding models like public-private partnerships and building strong coalitions of stakeholders to advocate for resources. Specific recommendations were made to synergize funding cycles, make joint agency grants, and modify RFP requirements to make it easier for private sector applicants.\nChampions, Policy Levers, and Community Engagement: Making progress requires action at multiple levels, from high-level policy coordination down to grassroots community organizing. Updating strategic plans and policy documents, establishing cross-agency working groups, and forging agreements between agencies all have a role to play. Scientific societies and other stakeholder groups are essential partners in advocating for needs and holding agencies accountable. The research community must lead the push for change as agency staff are constrained in their ability to lobby. Likewise, agency champions and core leaders willing to do the hard work of relationship-building across organizations are critical.\n\n\n\n\n\n\n\n\n\n\n\nTop recommendations:\n\nInvolve private sector for funding and tool development (short term high feasibility medium importance)\nEstablish small governance/working group and subcommittees (short term high feasibility high importance)\nPhase implementation plans to agency goals and programs (short term high feasibility high importance)\nStructure funding for cross-agency and center level efforts (medium term medium feasibility high importance)\n\nKey challenges: Coordination of effort and labor across agencies, Incentives favor new development over reuse Cross-agency funding challenges\nKey benefits: Increased capacity, Interoperability, Better documentation and training\nUse cases can help frame the importance of ecological forecasting for different audiences (economics, national security, etc.)\n\n\n\n\n\nDiscussed a range of funding opportunities at different scales, from large center grants to agency announcements and workshops\nSuggested lining up data services and engaging agencies to gather requirements, potentially through multi-agency workshops\nRecommended demonstration projects and high-priority follow-ups from this workshop to show value\nHighlighted opportunities around transition periods (e.g., new administrations) if you have connections\nEmphasized importance of both career-level and external champions (professional societies, networks)\nNoted communication challenges in translating forecasting importance to different audiences\n\n\n\n\n\nNeed to align forecasting with agency missions and identify champions at multiple levels\nOpportunities to tie into major current initiatives like the infrastructure bill, climate, carbon removal\nEngage boundary organizations, cooperative institutes, and advisory boards to influence priorities\nReframe forecasting around societally relevant issues beyond ecology (economics, health, etc.)\nChallenges with interoperability across agency systems need top-down pressure to force it\nPilot projects and regional centers could demonstrate value of collaboration\nInternational examples may provide useful models despite differences\n\n\n\n\n\nTop recommendations:\n\nProduce white paper to support champions in making the case (short term); AMS effort may help\nHave participants identify internal champions at their organizations (short term)\nEngage local and regional entities to demonstrate use cases and grow adoption (medium term)\nEnlist scientific societies to advocate for interagency collaboration (short-medium term)\n\nMissing plans for private sector engagement, international dimensions, distinguishing development vs operational infrastructure\nLocal/regional focus important as that’s where lots of management needs and decisions are\nChallenge is agency folks are burned out on interagency efforts so societies may need to lead advocacy\n\n\n\n\n\nEcological forecasting is fundamentally about operational, not just research, infrastructure - need to emphasize this\nCloud is the future, but focus should be on architectures and tools that enable interoperability, not commercial services; existing HPC investments can be leveraged\nEFI can influence agencies in the middle and through bottom-up community building; need an “EFI stack”\nMajor opportunity for EFI to lead training to build a workforce and change culture like the TOPS program did\nNeed to rebrand around the crosscutting nature of ecological forecasting to break down silos\n\n\n\n\n\n\nEmpowering Champions and Engaging in Advocacy: All groups emphasized the critical importance of finding and supporting champions at multiple levels within agencies and equipping them with compelling communication tools. Engaging external influencers and advocates was also seen as essential for building a broad coalition of support and for engaging with advocacy on the hill and elsewhere. Specific recommendations included:\n\nDevelop compelling communication materials such as case studies and success stories to equip champions to advocate for ecological forecasting.\n\nProduce a white paper to provide leverage to identified champions to explain the needs for ecological forecasting infrastructure and funding.\nCoordinate with the American Meteorological Society (AMS), which is already planning such a white paper.\n\nAttendees from this workshop should return to their home institutions and organizations and work to identify internal champions for ecological forecasting at various levels. Many people actually building the infrastructure may not know who the appropriate high-level champions are.\nHave multiple scientific societies (ESA, AGU, AMS, etc.) advocate through their policy arms for the importance of interagency collaboration on ecological forecasting cyberinfrastructure.\nDevelop flagship projects demonstrating the value of ecological forecasting that can be “shopped around” to potential champions and funders as examples of the promise and importance of the approach.\nStrategically leverage windows of opportunity such as administration transitions, budget cycles, or high-profile initiatives.\n\nDemonstrating Value through Pilot Projects and Partnerships:Many groups recommended investing in demonstration projects, pilot efforts, rebranding efforts, and local/regional partnerships as a way to showcase the tangible benefits of ecological forecasting and build grassroots engagement. Co-development of use cases and requirements with diverse stakeholders, including underrepresented and frontline communities, was seen as critical for ensuring broad relevance and adoption. Sharing success stories, best practices, and lessons learned from these early efforts can help build momentum and make the case for sustained investment and scaling of capabilities. Connecting forecasts to real-world decisions and outcomes is key.\nAligning with Agency Missions and Priorities: To gain traction in a resource-constrained environment, groups advised reframing ecological forecasting in terms of broader agency missions and societal priorities, such as economic development, public health, food and water security, hazard resilience, and environmental justice. Mapping efforts to high-profile initiatives (e.g., climate adaptation, infrastructure planning, sustainable development goals) and leveraging existing resources, programs, and policy hooks was seen as a promising strategy. Boundary organizations, cooperative institutes, extension programs, and other trusted intermediaries can play a valuable role in translating needs, priorities, and opportunities across stakeholder groups.\nFostering Interoperability and Reuse: Many groups noted the challenges posed by current agency IT environments, which are often characterized by fragmented, siloed systems, incompatible data formats, security constraints, and duplicative efforts. Improving the interoperability and reusability of cyberinfrastructure components was seen as critical for achieving the full potential of ecological forecasting. Strategies included developing community standards and protocols, adopting modular architectures and loosely coupled interfaces, and investing in training and community building efforts to promote best practices. While the shift to cloud computing was seen as an opportunity to rethink architectures and enable more seamless cross-organization workflows, participants cautioned against an overreliance on commercial vendor services like AWS, which can lead to lock-in and hinder portability. The focus should be on open, vendor-agnostic solutions that can integrate with existing on-premise investments and provide a migration path for resource-constrained partners.\nExpanding and Sustaining the Workforce: Several groups highlighted the importance of workforce development as a key enabler for ecological forecasting, noting that current training programs often fail to provide the unique blend of skills needed. Efforts to develop core competencies and establish best practices were seen as critical for doing the work of ecological forecasting but also for fostering long term synchrony and a culture of cooperation across agencies. Programs like the NASA TOPS and Openscapes initiatives were highlighted as potential models. Engaging university partners to modernize curricula, creating professional development opportunities for existing staff, and building bridges to new communities with relevant expertise (e.g., data science, software engineering) were all seen as important strategies.\nEnabling Bottom-Up Innovation: While top-down coordination is important, groups also emphasized the need to enable bottom-up innovation and organic community building. EFI was seen as well positioned to play a boundary-spanning role, both influencing agencies through its collective expertise and facilitating grassroots collaboration. EFI could provide the community with tools, training, and platforms to advocate for ecological forecasting priorities. Concepts like an “EFI technology stack” were proposed as a model for community-driven infrastructure development.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nTime\nActivity\n\n\n\n\nApril 10\n8:30 - 9:00 am\nWelcome Coffee & Tea\n\n\n\n9:00 - 10:00 am\nOverview of Workshop Goals and Why We Are Here  Leads: Workshop Organizing Committee\n\n\n\n10:00 - 11:00 am\nDesign Justice Principles Primer  Lead: Sean Dorr, University of Minnesota\n\n\n\n11:00 - 11:15 am\nCoffee and Tea Break\n\n\n\n11:15 - 12:00 pm\nDesign Justice Principles Activity  Lead: Sean Dorr, University of Minnesota\n\n\n\n12:00 - 12:10 pm\nGroup Photo\n\n\n\n12:10 - 1:30 pm\nLunch\n\n\n\n1:30 - 3:30 pm\nState-of-the-art Forecasting Workflows and Best Practices Presentations\n\n\n\n\n- Istem Fer, Finnish Meteorological Institute: What could an operational agricultural forecasting CI look like? Field Observatory Network (FiON) model-data workflows and services\n\n\n\n\n- David Watkins, U.S. Geological Survey: Forecasting infrastructure in context: lessons learned from greenfield forecasting projects\n\n\n\n\n- Clarissa Anderson, University of California San Diego and Southern California Coastal Ocean Observing System: Development of a Harmful Algal Bloom (HAB) Data Assembly Center in support of a National HAB Observing Network\n\n\n\n\n- Quinn Thomas, Virginia Tech, and Carl Boettiger, University of California Berkeley: Adventures from a million forecast march: community driven-CI for ecological forecasting\n\n\n\n\n- Alexandra Kirk (virtual), National Aeronautics and Space Administration IMPACT: VEDA, an open-source open-science platform for Earth Observation data\n\n\n\n\n- Renato Figueiredo, University of Florida: From FLARE to FaaSr: Towards Reusable Scalable Cross-Platform Cloud Native Workflows\n\n\n\n3:30 - 3:45 pm\nCoffee and Tea Break\n\n\n\n3:45 - 5:00 pm\nBreakout Group Discussions: What are common best practices and current technical gaps?\n\n\n\n5:00 pm\nEnd of Day 1\n\n\nApril 11\n8:30 - 9:00 am\nWelcome Coffee & Tea\n\n\n\n9:00 - 9:10 am\nRecap of Day 1 and Overview of Day 2  Lead: Jake Zwart\n\n\n\n9:10 - 10:15 am\nGaps, Barriers, and Other Challenges Presentations\n\n\n\n\n- Mike Dietze, Boston University\n\n\n\n\n- Marie Colton, Hydros LLC\n\n\n\n\n- David Scheurer, NOAA Ocean Service\n\n\n\n10:15 - 10:30 am\nCoffee & Tea Break\n\n\n\n10:30 - 12:00 pm\nBreakout Group Discussions: Synthesize common gaps, barriers, and challenges\n\n\n\n\nRecommendations for overcoming common gaps and barriers\n\n\n\n12:00 - 1:30 pm\nLunch\n\n\n\n1:30 - 3:00 pm\nBreakout Group Discussions: Propose generalized cyberinfrastructure design for ecological forecasting\n\n\n\n3:00 - 3:15 pm\nCoffee & Tea Break\n\n\n\n3:15 - 3:45 pm\nReport out on Proposed Generalized Cyberinfrastructure Design  Lead: Jake Zwart\n\n\n\n3:45 - 4:00 pm\nBio Break\n\n\n\n4:00 - 5:00 pm\nImplementation and Coordination by Organizations and Agencies  Leads: Jessica Burnett and Christopher Brown  Panel discussion:\n\n\n\n\n- Clarissa Anderson, UCSD & SCCOOS\n\n\n\n\n- Stinger Guala, NASA Earth Science Data Systems\n\n\n\n\n- Marie Colton, Hydros LLC\n\n\n\n\n- David Scheurer, NOAA Ocean Service\n\n\n\n\n- Steve Marley, NOAA Satellite & Information Service\n\n\n\n\n- Bruce Wilson, ORNL Distributed Active Archive Center\n\n\n\n5:00 pm\nEnd of Day 2\n\n\nApril 12\n8:30 - 9:00 am\nWelcome Coffee & Tea\n\n\n\n9:00 - 9:10 am\nRecap of Day 2 and Overview of Day 3  Lead: Jake Zwart\n\n\n\n9:10 - 10:45 am\nImplementation and Coordination by Organizations and Agencies  Leads: Jessica Burnett and Christopher Brown  Breakout group discussions\n\n\n\n10:45 - 11:00 am\nCoffee & Tea Break\n\n\n\n11:00 - 11:45 am\nReport out on Implementation and Coordination  Leads: Jessica Burnett and Christopher Brown\n\n\n\n11:45 - 12:00 pm\nClosing Remarks and End of Workshop  Lead: Workshop organizing committee"
  },
  {
    "objectID": "workshopsummary/summary.html#april-10th-wednesday---day-1-of-workshop",
    "href": "workshopsummary/summary.html#april-10th-wednesday---day-1-of-workshop",
    "title": " EFI-CI Workshop Summary",
    "section": "",
    "text": "Jake Kritzer, Executive Director of NERACOOS, welcomed everyone and read a letter from Congressman Chris Pappas highlighting the importance of the workshop’s work on improving ecological forecasting systems. This is critical for preparing coastal New Hampshire communities like Portsmouth for impacts of climate change, including severe flooding from storm surges and sea level rise that have already caused millions in damage.\nMike Dietze, EFI Steering Committee Chair, provided an overview of the Ecological Forecasting Initiative (EFI). EFI formally launched in 2018 aiming to build an interdisciplinary community of practice around making ecological science more predictive and useful to society. It involves participants from academia, agencies, industry, and NGOs across disciplines like ecology, computer science, and social science. Key EFI activities include: - Hosting workshops, conferences, and sessions at major meetings - Organizing working groups on cross-cutting challenges like cyberinfrastructure, theory, decision support, education, and diversity - Education/training efforts like courses, webinars, and mentoring programs - Developing products like policy briefs and reports with agency partners - The ongoing NEON Forecast Challenge engaging over 32,000 forecasts so far - Community building through a Slack workspace, newsletters, and social media\nJake Zwart from USGS reviewed the specific background motivating this cyberinfrastructure workshop, tracing back to a 2016 meeting discussing the gap between ecological forecasting research funded by NSF and lack of operational implementations. The 2019 USGS report and 2020-2022 interagency roundtables identified cyberinfrastructure and stakeholder engagement as the biggest needs for transitioning forecasts to operations.\nThe main goals for this workshop are:\n\nDocument current CI practices across different forecasting projects\nIdentify common CI needs and gaps\nPropose a CI design to support various ecological forecasting applications\n\nThe primary outcome will be a living online “CI handbook” hosted on GitHub’s EFI organization synthesizing recommended practices. There is also potential for a future workshop on the research-to-operations gap.\nCameron Thompson discussed the process for developing the CI handbook by synthesizing input and findings from presentations, discussions, breakouts and documentation at this workshop. He reviewed the FAIR data principles (findable, accessible, interoperable, reusable) and introduced the CARE principles (collective benefit, authority to control, responsibility, ethics) which extend data governance considerations to indigenous data sovereignty. An interactive poll using PollEverywhere asked participants to define the boundary between “small” and “medium” size ecological forecasts to explore establishing a common vocabulary.\n\n\n\nSean Dorr and Melissa Kenney gave a joint presentation on applying design justice principles to improve the understandability and service equity of ecological forecasts.\nSean Dorr introduced himself as an Ojibwe tribal member and 4th year Computer Science PhD student at the University of Minnesota. His research focuses on incorporating indigenous perspectives into data visualization and human-computer interaction, bridging different worldviews.\nSean reviewed his work applying design justice principles with the Ecological Forecasting Initiative (EFI) community. Design justice centers people normally marginalized by design and uses collaborative creative practices to address community challenges. Key activities included:\n\nReviewing EFI projects against the 10 design justice principles to identify who is included/excluded\nPositionality exercise mapping education, geography, hobbies, skills, languages, career level, demographics, and values of participants\nCrafting engagements and paths forward to realize design justice with excluded communities\n\nEarly insights emphasized the importance of clearly defining “we,” “community,” and “designers,” identifying positionality, and applying the principles concretely.\nMelissa Kenney shared lessons learned from over a decade of research at the University of Minnesota to improve the understandability of environmental decision support products:\n\nVisualize the main story, nothing more\nSubjective feedback can be misleading\nEmpirical testing accelerates user-centered changes\nInteractive products require revisiting visualization norms\nEarly co-production with diverse users improves equity\n\nExamples included improving National Climate Assessment indicators, USGS water supply outlooks, NOAA temperature/precipitation outlooks, and drought monitors through redesign and controlled testing. She emphasized the power of empirical evaluation to drive research-to-operations improvements.\nMelissa also discussed an ongoing NOAA project to co-develop equitable flood and drought projections for the Upper Mississippi River basin by integrating climate models and engaging impacted communities. Building long-term relationships enables research questions and products to be transformed to better serve diverse users.\nIn the Q&A, they discussed strategies for expanding user testing as demands evolve and making the design justice approach scalable for resource-constrained agencies. Sean and Melissa welcomed follow-up discussions to provide feedback on specific visualizations.\n\n\n\n\nIn the Design Justice Principles activity session, participants worked in small groups to apply design justice principles to a specific goal: creating cyberinfrastructure that supports workflows for communities with limited Internet access. The activity had two parts:\n\nCrafting Engagements: Groups selected a relevant design justice principle and brainstormed ways to engage the community to achieve the goal, placing ideas on sticky notes along a spectrum from small to big effort.\nCrafting Paths Forward: Groups completed sentences to articulate how a selected engagement would lead to realizing the design justice principle, identifying metrics of success and envisioning long-term results.\n\n\n\n\nGroup 1: Focused on Principle 6 (everyone is an expert based on lived experience). They proposed finding boundary organizations to collaborate with the community, holding town halls with follow-up, and building shared resources. Success metrics included the percentage of community members using provided services. Long-term results envisioned a community forum to improve access.\nGroup 2: Selected Principle 10 (look for what’s already working at the community level). They suggested attending community events to understand current information flows and access. Knowing what information is used and how would enable developing a broader science communication toolkit tailored to community needs.\nGroup 3: Chose Principle 3 (prioritize design impact over designer intentions). They proposed engaging middle school students in and out of school to introduce data products, observe their interaction, and learn about community access needs. Students would share learnings with their families, expanding awareness.\nGroup 4: Also focused on Principle 3. With farmers as the community, they emphasized iterative feedback to prioritize design impact. Growing and retaining diverse feedback participants would indicate progress. Long-term results included having the feedback process adopted by others.\nGroup 5: Initially considered Principles 3 and 10 but settled on Principle 2 (center voices of those directly impacted). For rural and tribal college students with limited resources, they proposed iterative discussions to identify needed data products, test prototypes, and build community capacity to drive the process over time.\nGroup 6: Selected Principle 10 and some of 2. They suggested interviews/surveys to discover what already works and doesn’t work for Internet-limited communities. Identifying unexpected solutions and unrecognized problems would demonstrate progress. Long-term products should integrate with existing community practices.\nGroup 7: Emphasized Principle 3. They proposed collaborating via an on-site workshop to understand the design’s potential community impact. The community agreeing that the goals were communicated and the product was transformed would indicate success. Ongoing engagement and iteration were envisioned long-term.\n\nThe activity helped participants start orienting their thinking around design justice considerations even when working on cyberinfrastructure that may seem removed from people. The presenter emphasized that software always involves people—developers, users, collaborators—and encouraged the group to keep this human-centered lens throughout the workshop.\n\n\n\n\n\n\n\nIstem Fer, a senior researcher at the Finnish Meteorological Institute, presented on their work developing a cyberinfrastructure for agricultural carbon and greenhouse gas monitoring, modeling, and forecasting in Finland. Their goal is to quantify the impacts of regenerative agriculture practices and provide decision support to a range of stakeholders, with farmers as the primary end users.\nKey challenges they face include:\n\nThe need to work with multiple models, each with different operation input/output formats and programming languages\nThe models are heavily parameterized and data-intensive to configure, initialize, and calibrate\nThe workflows require advanced computing and complex automation\n\nTo address the challenges, they adopted an existing community cyberinfrastructure called PEcAn (Predictive Ecosystem Analyzer). PEcAn wraps around different process-based models, standardizing and automating the data flows and other tasks. Their typical workflow ingests a variety of field data, propagates uncertainty via model ensembles, performs calibration and data assimilation, and disseminates results via an online Field Observatory service.\nOne operational example is a 15-day iterative carbon flux forecast that assimilates data to adjust model states each day. However, most of their models are not yet compatible with formal data assimilation.\nTo improve scalability, they are in the process of migrating from traditional servers to a cloud-based Openshift cluster. Their wish list also includes enhancing the PEcAn API for 3rd party access, addressing model-data bottlenecks that hinder further scaling, providing more decision-relevant seasonal forecasts for farmers, and integrating with other EFI cyberinfrastructure such as forecast scoring standards.\nIn summary, the project is driven by stakeholder demand but still working on researcher adoption. PEcAn was chosen to enable the key need of multi-model interoperability. Openness, version control, modularity, and virtualization were important design elements. Despite the agricultural context, many aspects may serve as best practices for ecological forecasting cyberinfrastructure more broadly.\n\n\n\nDavid Watkins, a machine learning engineer with the USGS Water Mission Area, shared lessons learned from developing cyberinfrastructure for forecasting projects over the past few years, starting from a greenfield situation.\nHe emphasized thinking about the infrastructure in the broader context of batch vs. streaming data processing paradigms. USGS forecasting use cases like stream temperature, drought, and chlorophyll-a fall into the batch processing category, with forecasts running nightly to incorporate the previous day’s data.\nTheir initial stream temperature project had to prioritize speed and minimize new tools due to a short turnaround, leading them to incur technical debt. For the longer-term drought and temperature projects, priorities shifted to using a modern cloud-based approach for longevity, ease of maintenance via serverless services, and simplicity (e.g., repetitive daily processing vs. duplicating data stores).\nTheir current tech stack includes AWS Step Functions for orchestration, Docker for environment control, AWS Fargate/ECS, SageMaker, and S3 for compute and storage, GitLab for CI/CD pipelines, and CloudFormation for infrastructure-as-code.\nPatterns for success they’ve identified include:\n\nReproducible practices becoming non-negotiable\nModularity for debugging\nDiverse skills (software, modeling, visualization, outreach) in a cross-functional team\nPlanning for operations from the start\n\nTheir wish list includes more infrastructure staff, exploring ML-specific tools for experiment tracking, model registries, and feature stores, and increasing standardization across projects and organizations.\nIn the Q&A, David welcomed input on making this type of overview relevant for both machine learning and process-based modeling applications in the audience.\n\n\n\nClarissa Anderson from UC San Diego and the Southern California Coastal Ocean Observing System (SCCOOS) presented their work developing a prototype Harmful Algal Bloom (HAB) Data Assembly Center as part of the U.S. National HAB Observing Network (NHABON).\nThe HAB problem in California is primarily due to the diatom Pseudo-nitzschia and the neurotoxin domoic acid it produces, which has impacted fisheries, marine mammals, and public health. While there is a long history of HAB monitoring and modeling in California, the Imaging FlowCytobot (IFCB) network provides a new opportunity for near real-time, high-resolution observation of phytoplankton communities.\nWith funding from the NOAA NCCOS HAB Community Technology Accelerator project, they are developing the HAB Data Assembly Center to provide centralized cyberinfrastructure for the IFCB network.\nKey elements include:\n\nAutomated data accession, image processing, and product generation\nClassifier training, evaluation, and application tools\nStandardized community annotation workflows\nOpen source best practices for software, methods, and metadata\n\nThe Transition Advisory Committee helps identify barriers and broaden the scope beyond California. Priorities include extending to other regions, engaging diverse stakeholders, and finding a sustainable home for the system.\nDownstream applications have included a daily alert system for managers, morphometric trait databases for ecosystem modelers, and transformations to push data to repositories like OBIS.\nTheir wish list includes plug-and-play instrument integration, expanded regional nodes, more management-tailored products, and an instrument-agnostic evolution into a general Plankton Data Assembly Center with community-wide standards for imagery data.\n\n\n\n\nCarl Boettiger started with principles for designing cyberinfrastructure to make it easier to integrate the explosion of ecological data and forecasting methods. Key points included:\n\nThe “Lego principle” - components should be modular, reusable, and interoperable based on common standards without custom modifications that break compatibility\nAgreement on standards is critical - e.g., common table formats for forecasts\nUse of reproducible compute environments (e.g., Docker), S3 object storage, and range requests for efficient data access\n\nQuinn Thomas then shared stories of applying these principles in the NEON Ecological Forecasting Challenge, a platform that enables the ecological forecasting community to submit iterative near-term forecasts of NEON data before it is collected. Their journey included:\n\nTraining the community via workshops and template repositories\nAutomating daily forecast submission and evaluation using modular CI components\nScaling up from hundreds to thousands of forecasts per month by shifting to self-hosted runners\nExtending the platform to partner projects like LTER and USGS via a “forkable CI”\nDeveloping a clearinghouse of challenge catalogs to make grassroots efforts discoverable\n\nThroughout, adherence to common data and metadata standards allowed flexibility to adapt to growing scale and scope.\nTheir wish list includes further sharing of “Lego brick” components, increased multi-language support, and deeper engagement with the machine learning community.\nOverall, the presentation highlighted how careful CI design around modularity and standards from the beginning enables a community of forecasters to build and innovate together.\n\n\n\nRenato Figueiredo from the University of Florida (soon Oregon State University) presented work done in collaboration with Cayelan Carey and Quinn Thomas from Virginia Tech on extending their FLARE (Forecasting Lake and Reservoir Ecosystems) cyberinfrastructure to a more generalizable system called FaaSr.\nFLARE uses a cloud-based event-driven workflow leveraging Docker containers for reproducibility and Function-as-a-Service (FaaS) for serverless invocation of the containers. Intermediate data is stored in S3 buckets. The key goals were scalability, reproducibility, and low barriers to entry for development and deployment using R.\nWhile FLARE addressed specific project demands, FaaSr aims to generalize the approach to support:\n\nMultiple cloud FaaS providers without code changes\nComposition, sharing, and reuse of workflows\nDecoupling of workflow configuration from code\n\nFaaSr is an open-source R package that simplifies development and deployment of FaaS workflows. Users write functions in R, use S3 for data I/O, and describe the workflow composition in a JSON configuration. FaaSr automates the registration, execution, and orchestration of the workflow on different FaaS platforms (GitHub Actions, OpenWhisk, AWS Lambda).\nKey features include cross-platform support via Docker and S3, a GUI for visual workflow composition, and flexibility to use custom containers per function. Figueiredo demonstrated a NEON forecast example running with minimal code changes and a proof-of-concept for concurrent execution across platforms.\nThe wish list includes community resources like shared S3 buckets and OpenWhisk instances, improved usability through GUIs and cloud training, and community engagement for feedback, new features, and workflow sharing.\nFigueiredo expressed enthusiasm for collaborating with the ecological forecasting community and contributing to initiatives where possible.\n\n\n\nAlexandra Kirk, a cloud engineer at Development Seed, presented on behalf of the NASA IMPACT (Inter-agency Implementation and Advanced Concepts Team) on VEDA, an open platform that brings Earth science datasets to open-source tools for data processing and analysis.\nVEDA was initiated in response to the need for inter-agency collaboration and data sharing during COVID lockdowns when on-premise resources were unavailable. It has since evolved to reduce barriers to compute resources, data publishing, and sharing insights with both technical and non-technical audiences.\nKey elements of VEDA’s cyberinfrastructure include:\n\nOpen source Earth Observation API (EO-API) tools for bootstrapping a “stack catalog” with APIs and tiling resources for efficient data access\nModular components that enable multiple teams to assemble customized “VEDA stacks”\nContinuous development and improvement driven by community usage\n\nThe core workflow involves:\n\nTransforming data to analysis-ready cloud-optimized (ARCO) formats in S3 storage\nDeploying cloud compute resources (e.g., Jupyter Hubs) co-located with the data for efficient processing\nSharing data and insights back out via APIs, web applications, and dashboards\n\nThe EO-API infrastructure includes a PostgreSQL database with a STAC schema, a FastAPI service conforming to the STAC specification, and libraries for querying data by space, time, and properties.\nAn example of VEDA in action was scaling an algorithm developed by the NASA EIS Fire Tracking team from California to near real-time coverage of the Continental US. This involved integrating with the MAAP processing system, scheduling jobs, and publishing outputs to the VEDA API for dashboard visualization.\nKirk emphasized the importance of VEDA’s open modular design in enabling collaboration and continuous improvement through community usage. Documentation, tutorials, and a JupyterHub for hands-on exploration are available at the shared links.\n\n\n\n\nHassan asked where PEcAn gets its data from. Istem and others responded that it primarily uses public APIs.\nA question was posed about how NEON uses Docker. The response was that most researchers already have a local workflow and wouldn’t want to change it, so ideally the Docker usage is invisible and just works. However, power users would know what to do with Docker themselves.\nHassan inquired about reporting AI-generated data, including QA/QC. Clarissa explained that uncertainty metrics come out of the analysis, and while the ML process is an identification process, the data is real, not synthetic (though it may become interpolated). David added that the outputs aren’t particularly special, but the difference is in provenance tracking, which needs a specific identifier for things like training data.\nThere was a discussion about Open Geospatial Consortium standards. Carl mentioned that there is some tension and complexity in the evolution of standards through the OGC model versus the open-source community model.\nJake Zwart noted that Istem seemed to be the only one using an existing CI or workflow and asked others about their decision processes for adopting or developing workflows. Istem explained that she helped develop PEcAn, which solved problems similar to what she was working on. While it’s been difficult to get external groups to adopt it, it’s now more distributed, with mostly agricultural groups using it. Renato pointed out that a challenge with workflows is the infrastructure behind them, and moving to the cloud helps avoid infrastructure upkeep and lock-in.\nA question was raised about the risk of vendor lock-in when using cloud services. David responded that they use services in a fairly generic way, so while there would be some costs, they could migrate to another commercial cloud provider if needed. Renato added that moving to the cloud model already makes it easier to transition between platforms. Carl mentioned that they’ve already had experience with this issue.\nIstem asked how NEON and other challenges talk to each other. Quinn and Carl explained that they are linked at the catalog level, so a search for something like chlorophyll-a forecasts in Wisconsin could return results from different challenges. They also share fundamental packages and Docker containers. EFI made a strategic decision to keep the challenges separate to empower communities and maintain data sovereignty rather than forcing everything to go through EFI, which acts more as a clearinghouse for standards and components.\n\n\n\n\n\n\nBased on a comprehensive review of the breakout session notes, report-outs, and the broader context provided by the workshop presentations, several key themes, tensions, and challenges emerged regarding the current state and future development of ecological forecasting workflows.\n\n\nA dominant theme across all breakout groups was the crucial role of standards and best practices in enabling the development of robust, interoperable, and sustainable ecological forecasting workflows. There was also broad agreement on the need to “develop by using standard practices in other fields rather than reinventing them.” Groups emphasized the value of adopting and adapting existing standards and practices from fields such as software development, data management, and cloud computing. They discussed the importance of establishing community-wide conventions around data formats, metadata schemas, and workflow design patterns to facilitate collaboration, reproducibility, and scalability. Nevertheless, participants also recognized the challenge of balancing standardization with flexibility and adaptability. This tension between top-down standardization and bottom-up customization was a recurring theme, particularly in discussions around the differing needs of research and operational workflows.\n\n\n\nAnother major theme was the challenge of integrating and harmonizing heterogeneous data from diverse sources and formats. Participants highlighted this as a key bottleneck in ecological forecasting workflows, noting that “biological and ecological data is very hard to standardize.” As one group put it, “we thought that some physical data can be standardized… but it is challenging for biological and ecological data.” Furthermore, there was some disagreement about the feasibility and desirability of completely standardizing all ecological data types. Groups discussed the need for better tools, methods, and conventions to support data cleaning, transformation, integration, and provenance tracking. They also emphasized the importance of capturing and propagating uncertainty throughout the data lifecycle. Some participants suggested a more pragmatic approach with “even if not community-wide standard, a project standard will be useful.”\n\n\n\nCutting across many of the breakout discussions was a recognition of the vital importance of effective communication, collaboration, and cultural practices in advancing ecological forecasting workflows. As one group put it, ecological forecasting as a community and field was reaching a critical mass due to greater technology and data access, which enables rapid development and opportunity but also presents challenges. Participants repeatedly emphasized the need for closer collaboration and better communication between domain scientists, IT experts, and other key stakeholders.\nAs one group noted, IT experts may not address the right questions through their forecasting CI design, while a domain scientist may code a fragile system; thus, there needs to be intense communication between them. Likewise, another group called for engineer and scientist mutualism and synergy without siloing. Groups also discussed the importance of fostering a culture of openness, transparency, and continuous learning within the ecological forecasting community. They highlighted the need for better documentation, knowledge sharing, and training resources to support the adoption and long-term maintenance of best practices. However, participants also acknowledged the challenge of overcoming entrenched organizational and disciplinary silos, as well as the lack of incentives and rewards for investing in these kinds of activities. As one group put it, “a lot of these best practices really boiled down to software development best practices,” but “it was very important to also make sure to understand and articulate the motivation for the forecasting.”\n\n\n\nMany groups discussed the potential of cloud computing and modular, interoperable architectures to accelerate the development and deployment of ecological forecasting workflows. Participants highlighted the benefits of technologies such as containers, object storage, and serverless computing in enabling reproducibility, scalability, and flexibility. They also emphasized the value of breaking down complex workflows into smaller, reusable components that can be shared and recombined in different contexts.\nHowever, some groups also raised concerns about the potential risks and trade-offs associated with a wholesale move to the cloud, particularly around issues of vendor lock-in, long-term sustainability, and data sovereignty. Participants grappled with how to balance the benefits of leveraging industry tools and platforms with the need to retain control and ownership over critical infrastructure and data assets. As one participant put it, “Commercial providers are now subsuming some things that might have been viewed as having government roles but without the social contract that they do when they’re in government.”\n\n\n\nA recurring tension throughout the breakout discussions was the challenge of reconciling the differing needs, incentives, and constraints of research and operational environments. Groups highlighted the tension between research quality and production quality workflow, noting that each requires a different set of skills, tools, and practices. Participants discussed the difficulty of translating research models and workflows into production-ready systems, as well as the lack of communication and coordination between research and operational teams.\nSome groups emphasized the need for greater investment in the “human factors” and organizational aspects of ecological forecasting, such as training, documentation, and stakeholder engagement. They argued that “technology has reduced some barriers but more work is needed” and that “the people that we need aren’t necessarily engaged.” Participants also noted the tension between the scientific incentives for novelty and innovation and the operational requirements for stability, reliability, and continuity. As one group put it, “scientists and the systems they are in value innovation over stability, but what’s really needed is stability, which is not well-valued.”\n\n\n\nWhile not all groups engaged deeply with the design justice principles presented earlier in the workshop, there was a general recognition of the need to center equity, inclusion, and participation in the development of ecological forecasting workflows. Some participants highlighted the potential of cloud-based workflows to enable greater access and democratization, noting that “data in the cloud enable capacity development” and that “you don’t have to do the forecast on your own device.” Others emphasized the importance of engaging diverse stakeholders throughout the workflow lifecycle, from problem formulation through to the dissemination and use of forecasts. However, groups also acknowledged the significant challenges, noting that “access is probably the biggest issue right now” and that “some communities simply don’t have the wherewithal to even start looking.” They discussed the need for more intentional and proactive outreach to underrepresented groups, as well as the importance of designing workflows that are accessible and responsive to the needs and constraints of diverse users. Some groups also highlighted the challenges of ensuring transparency and accountability in the use of ecological forecasting workflows, particularly when working with aggregated or derived data products."
  },
  {
    "objectID": "workshopsummary/summary.html#april-11th-thursday---day-2-of-workshop",
    "href": "workshopsummary/summary.html#april-11th-thursday---day-2-of-workshop",
    "title": " EFI-CI Workshop Summary",
    "section": "",
    "text": "The biggest bottleneck is human capital and the steep learning curve required to operationalize a forecast. Shared tools and infrastructure are needed to flatten this curve.\nThe high cost (~$5M per forecast according to NASA) and learning curve create barriers to entry and major equity issues as it limits forecasts to data-rich systems and affluent countries rather than underserved communities that may need the information most.\nThe result is many individual “boutique” forecasting systems that don’t share code or methods. Community cyberinfrastructure is needed to share costs, avoid reinventing wheels, and make forecasts more interoperable and reusable.\nKey priorities for shared infrastructure include: standards/interoperability, scalable data ingest, automation tools, archiving and findability of forecasts and data, and assimilation/hybrid modeling methods.\nMost ecological forecasts are a “medium” scale - too big for manual methods but not big enough for dedicated infrastructure like the weather enterprise. Shared tools are essential for this scale.\nHowever, data volumes are rapidly increasing to petabyte scales, so some ecological forecasts may reach weather-like big data challenges soon.\nSustainability of shared infrastructure funding is a major unresolved challenge.\nCultural barriers include the “if you build it they will come” fallacy - community building and buy-in is essential, not just tool development.\nAcademics tend to get stuck in funding “ruts” and have difficulty branching out to other funding sources and partnerships.\nCoproduction with users is essential but very difficult in practice, especially for early-career researchers. Alternative partnership models are needed.\nOvercoming barriers requires fiscal and cultural buy-in as well as more training to flatten the learning curve.\n\n\n\n\n\nMarie has a background in physical oceanography and has worked at NASA, Navy, and NOAA. She advocates for building a forecasting culture to help people see and prepare for the future.\nThe vision is a National and International Ecological Forecasting Enterprise. Key questions include who it’s for, at what scale and impact, who operates the forecasts, and how to standardize curricula.\nIn 2014, the American Meteorological Society (AMS) Committee on Ecological Forecasting was established. Over the last 4 years as chair, Marie worked to get the AMS to endorse a formal statement on the future of ecological forecasting to organize and focus policy and funding. The statement was approved in January 2024. AMS Statement\nEcological forecasts need to identify relevant time and space scales. Marie showed examples linking standard weather service products to ecological phenomena that would need forecasts.\nEnvironmental security is a key driver - e.g., sinking islands displacing people. Forecasts need to incorporate economic and social equity dimensions.\nForecasts should start by identifying the decision/action needed as close to the decision point as possible. Environmental intelligence should synthesize data, science, management, and knowledge to meet stakeholder needs.\nMarie highlighted efforts like the NEON forecasting challenge and USGS HAB challenge as examples of research efforts that generate innovations that can eventually transition to operations.\nThe weather enterprise has doubled forecast skill in 15 years through consistent funding and systematic approaches. Marie advocates for leveraging existing operational infrastructure where possible for efficiency.\nMarie highlighted how the roles of the private sector have changed dramatically since 2003. Industry is now an instrument builder, data provider, model developer, and distributor of products. Cloud services are replacing government infrastructure. The workforce is Internet native.\nThe top industries for data scientists don’t explicitly include environment, but environment factors into all of them. Ecological forecasters can make connections and bring methodologies to the weather/climate modeling community.\nCyberinfrastructure needs include: compute power, data storage and I/O, federated systems, access frameworks, workflow tools, development environments, interactivity, and standards.\nNext steps include identifying stakeholders, consolidating needs, integrating forecasting across agencies, conducting workshops, categorizing products, defining platforms, quantifying infrastructure needs, developing governance structures, and focusing funding.\n\n\n\n\n\nDavid is the NOAA ecological forecasting portfolio manager. His talk covered NOAA’s ecological forecasting framework, progress on a national HAB forecasting system, and implications for cyberinfrastructure.\nNOAA’s ecological forecasting efforts build on its history in forecasting and leverage existing operational models and data where possible. Current focus areas are harmful algal blooms (HABs), hypoxia, pathogens, and living marine resources.\nDavid provided examples of operational forecast products for each focus area, highlighting the benefits, stakeholders, and components that go into each:\n\nGulf of Mexico HAB Forecast - predicts respiratory irritation risk, bloom location/extent\nChesapeake Bay Vibrio Forecast - predicts concentrations in oysters to guide shellfish harvesting\nLake Erie Hypoxia Forecast - predicts low oxygen events to aid drinking water management\nPuerto Rico Habitat Assessment - predicts fish biodiversity hotspots to inform spatial planning\n\nFoundational capabilities that support ecological forecasts include NOAA’s suite of operational forecast systems for the physical environment and extensive observing systems (satellites, in-situ monitoring).\nCollaborations and partnerships are essential, e.g., the Pacific Northwest HAB Bulletin involves coordination across a dozen federal, state, tribal, university, and nonprofit entities.\nNOAA has established a vision and requirements for a National HAB Forecasting System that weaves together regional systems into an operational framework. Key elements include co-development with stakeholders, transition plans, and research to improve operational capabilities.\nDavid walked through an example system anatomy and workflow for the Gulf of Maine HAB Forecast, highlighting areas of automation vs manual steps. Cyberinfrastructure improvements include documentation, automation, standardization, integration, and research-to-operations pathways.\nMajor technical gaps include standardization across regions, integration of multiple data streams, coupling with physical models, and stable computational resources for real-time vs scenario forecasts.\nCultural barriers include inconsistent nomenclature and expectations between research and operational groups.\nChallenges working across organizations include misalignment of mission needs affecting data sharing and extensive dependencies that create vulnerabilities.\nRecommendations include utilizing national frameworks tailored for regions, fostering the next generation of forecasters, and learning from ongoing efforts to consolidate operational systems.\n\n\n\n\n\nQuinn asked about the receptivity of agencies to adopt shared tools and approaches developed by the academic community. David said NOAA is moving toward more open-source frameworks but there are still constraints. Marie noted that transitions are costly and nonlinear so the most mature approaches should be prioritized through intercomparison projects. Unexpected funding opportunities can also accelerate progress.\nMike asked about the modularity and accessibility of NOAA’s Unified Forecast System for ecology. David said it depends on the topic - atmospheric and coastal modeling is further ahead but there is intent to incorporate ecological components, though fine scale resolution is a challenge. Marie highlighted the need to actually connect with HPC/modeling groups who have placeholders for ecological components but may not know how to implement them. Mission conflicts can also arise between physical and ecological model requirements.\nCarl asked about the role of incentives and funding structures in perpetuating barriers. Marie described how government performance metrics flow down to shape individual incentives. Strategic planning across agencies and program managers is needed to build more coordinated initiatives. Following the money flow reveals actual priorities.\n\n\n\n\n\n\n\n\n\nChris is a principal software engineer at Red Hat Research who started working with Dr. Mike Dietze on the PEcAn project in January 2023 to develop an asynchronous distributed cloud-native workflow for PEcAn.\nEcological forecasting researchers need open-source, accessible, reusable, and scalable software tools. PEcAn previously ran on high-performance computers which were not very accessible or scalable compared to the cloud.\nThe ecological forecasting team consisted of Boston University software engineers, graduate students, Professor Dietze, and Chris as the Red Hat software engineer. The Red Hat Collaboratory with BU is a partnership advancing research in emerging technologies.\nIn 2023, they prototyped an accessible community infrastructure to generate ecological forecasts at scale, focusing on an asynchronous, event-driven, distributed cloud-native workflow.\nThey deployed PEcAn on the New England Research Cloud (a shared cloud environment across several universities) using Kubernetes, PostgreSQL, RabbitMQ, and Jupyter notebooks. This allowed students and engineers to share the same cloud environment.\nKey open cloud solutions included open-source branching, distributed storage, pod auto-scaling based on messages, and an rsync strategy for transferring forecast data.\nRed Hat OpenShift provides an open-source, accessible, reusable, and scalable cloud platform for ecological forecasting from laptops to data centers. Chris demonstrated running PEcAn on his laptop using OpenShift.\nFuture milestones include an asynchronous event-driven scheduler, elastically launching data ingest containers, and supporting more sites/data/models. Successful collaborations involve subject matter experts, grad students, software engineers, and cloud computing resources.\n\n\n\n\n\nJake Zwart asked why Chris is enthusiastic about ecological forecasting. Chris said he enjoys helping communities with great ideas implement the enabling technologies, especially open web initiatives.\nHassan asked about APIs and interoperability in PEcAn. Mike Dietze listed several data sources ingested (e.g., NASA MODIS, flux net carbon, NEON data, etc).\nHassan asked about human capital, i.e., how many people are working on this. Mike answered that the PEcAn project has been around for 15 years and has had 84 pull requests; there are about 12 core developers, fluctuating based on funding.\nMike answering Hassan: Sustainability is difficult due to the ebb and flow of grants. PEcAn gets funding mostly through science-driven projects that also support infrastructure development rather than dedicated grants for the cyberinfrastructure alone. It’s an example of the problem of innovation being valued over sustainability in the funding environment.\nMike answering Hassan: Interoperability challenges arise from conflicts between modularity and provenance tracking that relied on a monolithic database.\n\n\n\n\n\nKelly is the data management lead for MARACOOS and Executive Director of RPS Ocean Science. She presented on the data management and cyberinfrastructure efforts of the U.S. Integrated Ocean Observing System (IOOS) and their transition to the cloud.\nIOOS brings together thousands of ocean observing datasets daily to support maritime safety, coastal resilience, ecosystem health, etc. The DMAC (data management and cyberinfrastructure) subsystem ensures the data is acquired, stored, quality-controlled, discoverable, accessible, and usable.\n\nUsability previously meant download but increasingly means Cloud compute via Jupyter notebooks.\n\nIOOS DMAC is transitioning to the cloud for improved scalability, continuity, cost-effectiveness, and alignment with NOAA’s cloud migration. However, it’s mostly been a “lift and shift” so far without optimizing for cloud-native architectures.\nThe “Reaching for the Cloud” project aimed to reduce barriers for data providers and users by developing a roadmap and cloud-native prototype solutions, especially for working with model data.\nIOOS RAs are challenged by working with forecast model outputs in Thredds.\nKey solutions included using Kerchunk and Zarr for cloud-optimized data representation, XPUBLISH for data access APIs, and automated event-driven workflows triggered by new data arriving in cloud storage.\nCase studies showed massive performance improvements for analyzing the 40-year Coastal Ocean Reanalysis dataset and the National Water Model using these cloud-native solutions.\nIOOS also developed a ‘coastal modeling cloud sandbox’ to enable collaborative development and efficient research-to-operations transitions. It provides a shared cloud environment with model code, input data, and HPC for testing.\nNext steps include expanding the sandbox for NOAA partners, archiving outputs to the cloud, and integrating with other IOOS cloud efforts. Getting NOAA buy-in leveraged existing relationships between the agency and cloud providers.\n\n\n\n\n\nRich asked if they had to iterate on chunk sizes when moving to the cloud. Kelly said yes, they experimented to find a balance between optimizing for time series extraction vs. whole-grid mapping.\nCarl asked how they got NOAA to agree to the cloud migration. Kelly said NOAA was already engaging with cloud providers for research partnerships, so IOOS leveraged those existing relationships which made cloud resources accessible. The transition felt organic as internal groups like CO-OPS were also naturally moving to the cloud.\n\n\n\n\n\n\n\n\n\nEcological forecasting encompasses a wide range of applications and domains of knowledge, each with unique requirements.\nForecasts vary in scales, requiring cyberinfrastructure that can accommodate this range.\nIdentifying commonalities while allowing for customization is a key challenge.\nGroup 1 proposed “validating the hypothesis that there are a manageable number of basic workflows that apply to all ecological forecasting tasks” as a starting point for identifying commonalities.\n\n\n\n\n\nAll groups discussed the role of standards in facilitating interoperability and reuse. However, they acknowledged that strict standards can limit flexibility and adoption.\nGroup 1 suggested standards should transcend specific formats and focus more on standardizing outputs than inputs. Group 4 proposed aiming for “common concepts for describing data” rather than rigid specifications.\nFocusing on standardizing outputs rather than inputs and borrowing conventions from other domains could help.\nCommunities of practice resist top-down standardization efforts that don’t include their input.\n\n\n\n\n\nGroups frequently mentioned the steep learning curve for existing forecasting tools and the overall difficulty of operationalizing a forecast as major challenges, particularly for less resourced organizations.\nStanding up a forecast requires not only domain knowledge but also data science, software engineering, and DevOps skills that are not traditionally part of ecology curricula. The field needs more dedicated research software engineers and data scientists.\nBetter documentation, code carpentry, and accessible training programs could help expand the pipeline and make forecasting more welcoming to inexperienced groups.\n\n\n\n\n\nLack of sustained funding makes it difficult to maintain forecasting cyber infrastructure long-term.\nGrant-funded academics struggle to operationalize and maintain systems once papers are published and money runs out. Even large agencies like NOAA struggle with continuity.\nGroups proposed a variety of approaches to pooling resources and advocating for investment. Grassroots efforts are valuable for building community but likely not sufficient.\n\n\n\n\n\nSocial and cultural barriers, not just technical ones, impede adoption of new forecasting approaches.\nRigid organizational requirements around security and procurement limit options for innovation.\nWorkers are “stuck in ruts” and habituated to familiar technologies and workflows. Switching to new shared systems means giving up some control and recognition which is not typically rewarded.\nInteroperability requires give and take between collaborators, but often organizations define their own conventions to meet immediate needs and maintain ownership. “Not invented here” mindset prevails.\n\n\n\n\n\nForecasts need to be designed with users’ decisions in mind, not just advancing science.\nThe groups agreed that stakeholder engagement is critical to designing relevant and usable forecasting products. However, cultivating those relationships is undervalued and takes substantial time and energy that is not always budgeted in research grants.\nAs group 3 pointed out, many current ecological forecasts are not actually designed to inform specific decisions. Connecting products to actions requires dialogue and trust-building that does not happen overnight.\nHigh-quality engagement is especially difficult with under-resourced and marginalized communities. A vicious cycle ensues where those most in need of information are least engaged in the process.\n\n\n\n\n\n\n\n\nDevelop community standards for model metadata, data formats, workflows, APIs, but adopt existing standards where available.\n\nSome groups further proposed focusing on standardizing concepts, not just variables and formats, to provide a more flexible foundation.\nIt was further noted that modular, loosely-coupled architecture can help minimize dependencies and allow for evolution of standards over time.\n\nIncentivizing the use of standards through funding requirements, community recognition, and demonstrated value for stakeholders could accelerate adoption.\n\n\n\n\n\nAll groups recognized that the success of cyberinfrastructure efforts depends on having people with the skills to develop, operate, and apply it effectively. Ecological forecasting requires a distinctive blend of domain knowledge, data science, statistics, and software engineering that is not adequately addressed.\nGroups called for a mix of strategies including developing a “skills pipeline” for students, enlisting professionals from the tech industry to contribute their expertise, and embedding “research software engineers and data scientists” within ecological forecasting teams rather than relying on domain scientists to develop technical capacities on top of their other responsibilities.\nProviding accessible, inclusive, and culturally-relevant training for diverse communities was seen as essential for broadening participation and ensuring the ethical development and application of forecasts.\n\n\n\n\n\nEngaging communities and stakeholders early and iteratively was identified as critical for ensuring that forecasting products are actually useful and used. Participants recognized that model development often happens in isolation from the communities it is intended to serve.\nGroup 1 called for “iteration between forecast producers and users” to refine products over time. They highlighted the need for “boundary organizations” to help translate needs and feedback across domains.\nGroup 3 posited that we should “build communities before we build tools” to center the user experience from the start. They suggested that human-centered design and design justice should be guiding principles for the community.\nGroup 5 noted that stakeholder engagement “requires dedicated time and funding” that is often not accounted for in current grant structures. Sustaining long-term collaborations requires shifts in the incentive structures of academia and agencies.\n\n\n\n\n\nParticipants recognized that a lack of discoverability and accessibility of existing models, data, and tools was a major barrier to efficient forecasting workflows. While valuable resources exist across the community, they are often siloed within particular organizations or projects. Recommendations for overcoming this barrier include:\n\nEstablishing a community catalog/archive for models, data, and tools\nIncorporating sample datasets and containerized environments in model archives\nEnabling cloud-based access to data from existing repositories\nShowcasing and rewarding examples of effective reuse of forecasts and tools\n\n\n\n\n\n\nAcross all groups, there was a recognition that cyberinfrastructure needs to be able to accommodate the diverse scales and applications of ecological forecasting and that a monolithic one-size-fits-all solution is unlikely to meet the community’s varied needs. Therefore, the groups suggested:\n\nFocusing on modular, loosely-coupled components that can be recombined in different ways for different use cases. Having well-defined interfaces between components can then enable adaptation for different needs.\nUtilizing cloud platforms for scalability while maintaining the ability to run locally\nSupporting multiple access modes (GUI, API, Jupyter notebooks) for different user groups\n\n\n\n\n\n\nDeveloping tools and platforms using open source software and development practices was seen as essential for building a collaborative, inclusive, and sustainable ecological forecasting community.\nProprietary tools and platforms can create barriers to entry and hinder interoperability.\nMeanwhile, open source approaches can enable faster progress by allowing the community to build on each other’s work and catch errors more quickly.\nTransparency and the ability to audit code will also build trust in forecasting methodologies and results.\nInvesting in the sustainability and maintenance of key open source tools and libraries that support forecasting, such as PEcAn, was seen as a high priority for funders.\nWhile open source was strongly advocated, participants also acknowledged the need to provide stable, supported platforms for operational forecasts which may require more formalized approaches.\n\n\n\n\n\nSecuring sustainable funding and establishing long-term partnerships across sectors was recognized as one of the most critical and challenging aspects of advancing ecological forecasting cyberinfrastructure.\nA number of strategies were suggested by groups to overcome this obstacle:\n\nEstablish long-term and diverse funding streams through cooperative agreements or public-private partnerships\nQuantify and communicate value of forecasts to stakeholders to encourage investment\nExplore cost-sharing approaches like in-kind computing contributions\n\nPartnerships and funding could then support:\n\nA dedicated “National Ecological Forecasting Center” that could serve as a hub for both research and operations.\nForecasting challenges with prizes\nCommunity-directed funding pools\n\n\n\n\n\n\nEmbedding design justice principles into the development of ecological forecasting cyberinfrastructure was lifted up as a priority, with groups observing that:\n\nEcological forecasting needs to partner with and center underrepresented communities in the design process, not just engage them as an afterthought.\nData colonialism has perpetuated harm, and indigenous data sovereignty needs to be respected.\nCultural relevance and accessibility should be considerations when evaluating proposals.\nCommunity partners need to be compensated for their time and expertise, and we shouldn’t just extract knowledge.\nPartnering with grassroots organizations, citizen science initiatives, and community-based monitoring networks was valuable\n\n\n\n\n\n\n\nWho do you consider to be the “we” as the designers of ecological forecasting CI?\n\nPractitioners actively developing forecasts and CI tools (Group 3)\nTechnologists and researchers involved in EFI from various sectors (Group 5)\nManagers setting strategy and advocating for resources (Group 1)\n\nWho do you consider to be the “community” we’re designing ecological forecasting CI for or with?\n\nForecast producers across agencies, academia, industry, NGOs (Group 1, 3)\nStakeholders and end users who will apply the forecasts (Group 1, 3)\nGeneral public, taxpayers, and communities impacted by forecast outcomes (Group 3)\nPotential future users and research community at large (Group 3)\n\nWho might be excluded in your list of design principles for ecological forecasting CI?\n\nTribal, indigenous, and underrepresented communities (Group 3, 4)\nGroups not present in the design process to advocate their needs (Group 3, 5)\nLess-resourced organizations unable to meet technical/data requirements (Group 1)\nThose uncomfortable with proposed technologies or resistant to change (Group 5)\n\nAre there ways to include these people with different design choices?\n\nProactively co-develop with marginalized groups from the start (Group 3, 4)\nEnsure broad representation of stakeholders in the design stage (Group 1)\nProvide accessible training and support for underserved groups (Group 3)\nMake tools modular and interoperable to reduce barriers to participation (Group 1)\n\n\n\n\n\n\n\n\nAdvocated for reactivating interagency activities with an ecological focus, serving as a clearinghouse.\nNoted that COVID impacted public-private partnerships and the need to re-engage.\nEmphasized the difficulty of writing contract deliverable proposals for the private sector and suggested agencies reconsider their RFP processes.\nStressed the importance of balancing the three pillars: public, private, and academic sectors.\n\n\n\n\n\nArgued that on-premise systems are coming to an end and transitioning to the cloud is inevitable.\nEmphasized the need for standardization to leverage resources effectively.\nSuggested that the community should develop standards and expand adoption until hitting a tipping point at which point agencies can be pushed to accept them.\nNoted that providing data in formats used by the forecasting community could save agencies money on grants.\n\n\n\n\n\nHighlighted that even within NOAA, there are cultural differences and collaboration barriers between line offices.\nSuggested that demonstrating successful cross-agency projects like the multi-stressor project could pave the way for more interagency funding opportunities.\nNoted that incentives for collaboration need to come from the top.\n\n\n\n\n\nShared examples of successful interagency coordination like the Civil Earth Observations initiative.\nNoted that the shift to cloud computing has broken traditional architectures because it changes how users interact with data.\nArgued that agencies are no longer driving technology development and are beholden to commercial cloud providers, leading to a loss of control.\nStressed that agencies need to collectively define their requirements for cloud services rather than just accepting what vendors offer. This could help provide market certainty for vendors while ensuring agency needs are met.\n\n\n\n\n\nProvided the multi-stressor project as an example of successful cross-agency collaboration within NOAA but noted it takes a lot of effort.\nSuggested updating policy documents to explicitly address interagency ecological forecasting needs.\nNoted that existing interagency agreements (IAAs) tend to be very topic-specific.\nProposed engaging with Congress to direct agencies to work together on ecological forecasting but since federal employees cannot lobby, this would have to be proposed by the EFI community.\n\n\n\n\n\nShared experiences working across multiple agencies as a contractor and noted that successful interagency collaborations exist but tend to be inflexible.\nEmphasized the importance of having project champions and executive sponsors to drive things forward while noting the challenges of finding people with the bandwidth to take on that role.\nHighlighted the importance of community building and the difficulty of coordination as initiatives grow beyond 100-150 people.\nWarned against the tendency for collaborative infrastructure efforts to try to meet everyone’s needs but end up serving no one well - “beware the monolith.”\n\n\n\n\n\n\nChris Brown asked Clarissa Anderson and David Scheurer about how to break down barriers between NOAA line offices. Clarissa suggested that incentives need to come from the top.\nMarie Colton proposed the idea of a “Fairweather Report” for ecological forecasting to engage different stakeholders and drive Congressional action.\nTyson Swetnam from the audience commented on the high costs of using commercial cloud services, particularly for academic research, and the importance of finding ways to manage egress charges.\n\n\n\n\n\nInteragency Collaboration: All panelists agreed that interagency collaboration is critical for advancing ecological forecasting CI but significant organizational, cultural, and technical barriers remain. However, there have been examples in the past of successful interagency initiatives. Top-down policy mandates, cross-agency demonstrator projects, and bottom-up community efforts were all seen as important mechanisms for driving progress.\nCloud Computing Disruption: The rapid and inevitable shift to cloud computing is upending traditional IT architectures, procurement models, and budget structures. As a result, agencies are spending more on operating costs and losing leverage to commercial providers. Coordinating requirements across agencies and presenting a unified front to vendors was seen as a potential solution to some of the challenges.\nImportance of Standards: Developing community-driven standards is essential for enabling interoperability, efficiency, and collaboration across disparate projects and organizations. Encouraging standards to emerge from the EFI community and reach a critical mass of adoption before being codified into agency policy was suggested as a strategy. Although standardization is important, panelists cautioned against over-specifying solutions or building monolithic systems that try to be everything to everyone. Cyberinfrastructure should remain modular, loosely coupled, and adaptable to the needs of different use cases. Finding the right balance is an ongoing challenge.\nSustainable Funding: Securing long-term stable funding for collaborative infrastructure projects is a major challenge. Panelists highlighted the importance of exploring creative funding models like public-private partnerships and building strong coalitions of stakeholders to advocate for resources. Specific recommendations were made to synergize funding cycles, make joint agency grants, and modify RFP requirements to make it easier for private sector applicants.\nChampions, Policy Levers, and Community Engagement: Making progress requires action at multiple levels, from high-level policy coordination down to grassroots community organizing. Updating strategic plans and policy documents, establishing cross-agency working groups, and forging agreements between agencies all have a role to play. Scientific societies and other stakeholder groups are essential partners in advocating for needs and holding agencies accountable. The research community must lead the push for change as agency staff are constrained in their ability to lobby. Likewise, agency champions and core leaders willing to do the hard work of relationship-building across organizations are critical."
  },
  {
    "objectID": "workshopsummary/summary.html#april-12th-friday---day-3-of-workshop",
    "href": "workshopsummary/summary.html#april-12th-friday---day-3-of-workshop",
    "title": " EFI-CI Workshop Summary",
    "section": "",
    "text": "Top recommendations:\n\nInvolve private sector for funding and tool development (short term high feasibility medium importance)\nEstablish small governance/working group and subcommittees (short term high feasibility high importance)\nPhase implementation plans to agency goals and programs (short term high feasibility high importance)\nStructure funding for cross-agency and center level efforts (medium term medium feasibility high importance)\n\nKey challenges: Coordination of effort and labor across agencies, Incentives favor new development over reuse Cross-agency funding challenges\nKey benefits: Increased capacity, Interoperability, Better documentation and training\nUse cases can help frame the importance of ecological forecasting for different audiences (economics, national security, etc.)\n\n\n\n\n\nDiscussed a range of funding opportunities at different scales, from large center grants to agency announcements and workshops\nSuggested lining up data services and engaging agencies to gather requirements, potentially through multi-agency workshops\nRecommended demonstration projects and high-priority follow-ups from this workshop to show value\nHighlighted opportunities around transition periods (e.g., new administrations) if you have connections\nEmphasized importance of both career-level and external champions (professional societies, networks)\nNoted communication challenges in translating forecasting importance to different audiences\n\n\n\n\n\nNeed to align forecasting with agency missions and identify champions at multiple levels\nOpportunities to tie into major current initiatives like the infrastructure bill, climate, carbon removal\nEngage boundary organizations, cooperative institutes, and advisory boards to influence priorities\nReframe forecasting around societally relevant issues beyond ecology (economics, health, etc.)\nChallenges with interoperability across agency systems need top-down pressure to force it\nPilot projects and regional centers could demonstrate value of collaboration\nInternational examples may provide useful models despite differences\n\n\n\n\n\nTop recommendations:\n\nProduce white paper to support champions in making the case (short term); AMS effort may help\nHave participants identify internal champions at their organizations (short term)\nEngage local and regional entities to demonstrate use cases and grow adoption (medium term)\nEnlist scientific societies to advocate for interagency collaboration (short-medium term)\n\nMissing plans for private sector engagement, international dimensions, distinguishing development vs operational infrastructure\nLocal/regional focus important as that’s where lots of management needs and decisions are\nChallenge is agency folks are burned out on interagency efforts so societies may need to lead advocacy\n\n\n\n\n\nEcological forecasting is fundamentally about operational, not just research, infrastructure - need to emphasize this\nCloud is the future, but focus should be on architectures and tools that enable interoperability, not commercial services; existing HPC investments can be leveraged\nEFI can influence agencies in the middle and through bottom-up community building; need an “EFI stack”\nMajor opportunity for EFI to lead training to build a workforce and change culture like the TOPS program did\nNeed to rebrand around the crosscutting nature of ecological forecasting to break down silos\n\n\n\n\n\n\nEmpowering Champions and Engaging in Advocacy: All groups emphasized the critical importance of finding and supporting champions at multiple levels within agencies and equipping them with compelling communication tools. Engaging external influencers and advocates was also seen as essential for building a broad coalition of support and for engaging with advocacy on the hill and elsewhere. Specific recommendations included:\n\nDevelop compelling communication materials such as case studies and success stories to equip champions to advocate for ecological forecasting.\n\nProduce a white paper to provide leverage to identified champions to explain the needs for ecological forecasting infrastructure and funding.\nCoordinate with the American Meteorological Society (AMS), which is already planning such a white paper.\n\nAttendees from this workshop should return to their home institutions and organizations and work to identify internal champions for ecological forecasting at various levels. Many people actually building the infrastructure may not know who the appropriate high-level champions are.\nHave multiple scientific societies (ESA, AGU, AMS, etc.) advocate through their policy arms for the importance of interagency collaboration on ecological forecasting cyberinfrastructure.\nDevelop flagship projects demonstrating the value of ecological forecasting that can be “shopped around” to potential champions and funders as examples of the promise and importance of the approach.\nStrategically leverage windows of opportunity such as administration transitions, budget cycles, or high-profile initiatives.\n\nDemonstrating Value through Pilot Projects and Partnerships:Many groups recommended investing in demonstration projects, pilot efforts, rebranding efforts, and local/regional partnerships as a way to showcase the tangible benefits of ecological forecasting and build grassroots engagement. Co-development of use cases and requirements with diverse stakeholders, including underrepresented and frontline communities, was seen as critical for ensuring broad relevance and adoption. Sharing success stories, best practices, and lessons learned from these early efforts can help build momentum and make the case for sustained investment and scaling of capabilities. Connecting forecasts to real-world decisions and outcomes is key.\nAligning with Agency Missions and Priorities: To gain traction in a resource-constrained environment, groups advised reframing ecological forecasting in terms of broader agency missions and societal priorities, such as economic development, public health, food and water security, hazard resilience, and environmental justice. Mapping efforts to high-profile initiatives (e.g., climate adaptation, infrastructure planning, sustainable development goals) and leveraging existing resources, programs, and policy hooks was seen as a promising strategy. Boundary organizations, cooperative institutes, extension programs, and other trusted intermediaries can play a valuable role in translating needs, priorities, and opportunities across stakeholder groups.\nFostering Interoperability and Reuse: Many groups noted the challenges posed by current agency IT environments, which are often characterized by fragmented, siloed systems, incompatible data formats, security constraints, and duplicative efforts. Improving the interoperability and reusability of cyberinfrastructure components was seen as critical for achieving the full potential of ecological forecasting. Strategies included developing community standards and protocols, adopting modular architectures and loosely coupled interfaces, and investing in training and community building efforts to promote best practices. While the shift to cloud computing was seen as an opportunity to rethink architectures and enable more seamless cross-organization workflows, participants cautioned against an overreliance on commercial vendor services like AWS, which can lead to lock-in and hinder portability. The focus should be on open, vendor-agnostic solutions that can integrate with existing on-premise investments and provide a migration path for resource-constrained partners.\nExpanding and Sustaining the Workforce: Several groups highlighted the importance of workforce development as a key enabler for ecological forecasting, noting that current training programs often fail to provide the unique blend of skills needed. Efforts to develop core competencies and establish best practices were seen as critical for doing the work of ecological forecasting but also for fostering long term synchrony and a culture of cooperation across agencies. Programs like the NASA TOPS and Openscapes initiatives were highlighted as potential models. Engaging university partners to modernize curricula, creating professional development opportunities for existing staff, and building bridges to new communities with relevant expertise (e.g., data science, software engineering) were all seen as important strategies.\nEnabling Bottom-Up Innovation: While top-down coordination is important, groups also emphasized the need to enable bottom-up innovation and organic community building. EFI was seen as well positioned to play a boundary-spanning role, both influencing agencies through its collective expertise and facilitating grassroots collaboration. EFI could provide the community with tools, training, and platforms to advocate for ecological forecasting priorities. Concepts like an “EFI technology stack” were proposed as a model for community-driven infrastructure development."
  },
  {
    "objectID": "workshopsummary/summary.html#agenda",
    "href": "workshopsummary/summary.html#agenda",
    "title": " EFI-CI Workshop Summary",
    "section": "",
    "text": "Date\nTime\nActivity\n\n\n\n\nApril 10\n8:30 - 9:00 am\nWelcome Coffee & Tea\n\n\n\n9:00 - 10:00 am\nOverview of Workshop Goals and Why We Are Here  Leads: Workshop Organizing Committee\n\n\n\n10:00 - 11:00 am\nDesign Justice Principles Primer  Lead: Sean Dorr, University of Minnesota\n\n\n\n11:00 - 11:15 am\nCoffee and Tea Break\n\n\n\n11:15 - 12:00 pm\nDesign Justice Principles Activity  Lead: Sean Dorr, University of Minnesota\n\n\n\n12:00 - 12:10 pm\nGroup Photo\n\n\n\n12:10 - 1:30 pm\nLunch\n\n\n\n1:30 - 3:30 pm\nState-of-the-art Forecasting Workflows and Best Practices Presentations\n\n\n\n\n- Istem Fer, Finnish Meteorological Institute: What could an operational agricultural forecasting CI look like? Field Observatory Network (FiON) model-data workflows and services\n\n\n\n\n- David Watkins, U.S. Geological Survey: Forecasting infrastructure in context: lessons learned from greenfield forecasting projects\n\n\n\n\n- Clarissa Anderson, University of California San Diego and Southern California Coastal Ocean Observing System: Development of a Harmful Algal Bloom (HAB) Data Assembly Center in support of a National HAB Observing Network\n\n\n\n\n- Quinn Thomas, Virginia Tech, and Carl Boettiger, University of California Berkeley: Adventures from a million forecast march: community driven-CI for ecological forecasting\n\n\n\n\n- Alexandra Kirk (virtual), National Aeronautics and Space Administration IMPACT: VEDA, an open-source open-science platform for Earth Observation data\n\n\n\n\n- Renato Figueiredo, University of Florida: From FLARE to FaaSr: Towards Reusable Scalable Cross-Platform Cloud Native Workflows\n\n\n\n3:30 - 3:45 pm\nCoffee and Tea Break\n\n\n\n3:45 - 5:00 pm\nBreakout Group Discussions: What are common best practices and current technical gaps?\n\n\n\n5:00 pm\nEnd of Day 1\n\n\nApril 11\n8:30 - 9:00 am\nWelcome Coffee & Tea\n\n\n\n9:00 - 9:10 am\nRecap of Day 1 and Overview of Day 2  Lead: Jake Zwart\n\n\n\n9:10 - 10:15 am\nGaps, Barriers, and Other Challenges Presentations\n\n\n\n\n- Mike Dietze, Boston University\n\n\n\n\n- Marie Colton, Hydros LLC\n\n\n\n\n- David Scheurer, NOAA Ocean Service\n\n\n\n10:15 - 10:30 am\nCoffee & Tea Break\n\n\n\n10:30 - 12:00 pm\nBreakout Group Discussions: Synthesize common gaps, barriers, and challenges\n\n\n\n\nRecommendations for overcoming common gaps and barriers\n\n\n\n12:00 - 1:30 pm\nLunch\n\n\n\n1:30 - 3:00 pm\nBreakout Group Discussions: Propose generalized cyberinfrastructure design for ecological forecasting\n\n\n\n3:00 - 3:15 pm\nCoffee & Tea Break\n\n\n\n3:15 - 3:45 pm\nReport out on Proposed Generalized Cyberinfrastructure Design  Lead: Jake Zwart\n\n\n\n3:45 - 4:00 pm\nBio Break\n\n\n\n4:00 - 5:00 pm\nImplementation and Coordination by Organizations and Agencies  Leads: Jessica Burnett and Christopher Brown  Panel discussion:\n\n\n\n\n- Clarissa Anderson, UCSD & SCCOOS\n\n\n\n\n- Stinger Guala, NASA Earth Science Data Systems\n\n\n\n\n- Marie Colton, Hydros LLC\n\n\n\n\n- David Scheurer, NOAA Ocean Service\n\n\n\n\n- Steve Marley, NOAA Satellite & Information Service\n\n\n\n\n- Bruce Wilson, ORNL Distributed Active Archive Center\n\n\n\n5:00 pm\nEnd of Day 2\n\n\nApril 12\n8:30 - 9:00 am\nWelcome Coffee & Tea\n\n\n\n9:00 - 9:10 am\nRecap of Day 2 and Overview of Day 3  Lead: Jake Zwart\n\n\n\n9:10 - 10:45 am\nImplementation and Coordination by Organizations and Agencies  Leads: Jessica Burnett and Christopher Brown  Breakout group discussions\n\n\n\n10:45 - 11:00 am\nCoffee & Tea Break\n\n\n\n11:00 - 11:45 am\nReport out on Implementation and Coordination  Leads: Jessica Burnett and Christopher Brown\n\n\n\n11:45 - 12:00 pm\nClosing Remarks and End of Workshop  Lead: Workshop organizing committee"
  },
  {
    "objectID": "workshopsummary/brief.html",
    "href": "workshopsummary/brief.html",
    "title": " EFI-CI Briefing Paper",
    "section": "",
    "text": "Society increasingly faces environmental challenges that require people to make decisions based on what they think the future state of nature will be. To that end, ecological forecasting attempts to make predictions that inform decision-makers on the likely future state of the environment, and numerous predictive models have been developed. These models represent environmental processes and use real world data to make predictions, the results of which help us understand the natural world and give context to changes we observe. However, they are often run manually or using boutique and independently-developed workflows that are difficult to iteratively learn from and hinder our collective ability to efficiently generate forecasts. Meeting the challenge of making informed decisions in a rapidly changing world requires frequent, near-term, and reproducible ecological forecasts which are supported by robust cyberinfrastructure.\n\n\nCyberinfrastructure can facilitate our ability to create, improve, and learn from forecasts, but seemingly there is a lack of widely accepted cyberinfrastructure design principles which is a major obstacle for researchers and organizations seeking to engage in ecological forecasting. In an effort to address these obstacles, a workshop was convened by EFI and the Northeastern Regional Association for Coastal Ocean Observing Systems (NERACOOS) to: 1. Collate common cyberinfrastructure practices currently used 2. Identify cyberinfrastructure needs and gaps 3. Propose cyberinfrastructure designs for various forecasting problems\nThe workshop participants included a diverse mix of participants from various sectors including NGOs, private industry, academia, and federal agencies.\nThrough presentations, panels, and breakout sessions, participants discussed workflows, best practices, and the implementation of cyberinfrastructure across agencies. Although there were technical presentations, the makeup of participants influenced the scope of the topics covered and contributed to the majority of discussions focusing on higher level concepts and general design rather than the technical aspects of cyberinfrastructure. Often the participants’ recommendations reflected those that are in the literature, such as the FAIR principles which stipulate that data should be findable, accessible, interoperable, and reusable. Otherwise, their varied experiences and perspectives highlighted the many challenges which hinder adoption of best practices and advancement of ecological forecasting. Here we report on some of the major themes from the workshop and identify areas for advancing the implementation of cyberinfrastructure to support ecological forecasting.\n\n\n\nCyberinfrastructure refers to the integrated suite of hardware, software, data, and human resources designed to support data analysis and information processing. The design of cyberinfrastructure for ecological forecasting can take many different forms and the sequence of processes within that infrastructure constitutes the workflow. Cyberinfrastructure best practices include concepts like data standards and modularity which enable the workflow to be automated, flexible, and scalable. These workflow best practices are also aspects of cloud-based architecture which involves designing systems specifically to leverage cloud services and capabilities. However, cyberinfrastructure can adopt cloud-based architecture principles without using vendor cloud services. Doing so takes advantage of the flexible, scalable, efficient design while enabling local control and the use of cost-effective infrastructure like on-premises high-performance-computing systems.\nThe rapid and inevitable shift to cloud computing is upending traditional IT architectures, procurement models, and budget structures. Organizations risk cost inflation and loss of leverage to commercial providers when locking into cloud vendor services. Utilizing cloud-based architecture while minimizing reliance on services is a solution to some of the challenges and enables adoption of cyberinfrastructure best practices. Another strategy is to coordinate across agencies and other organizations to reach collective or at least transparent agreements on service requirements and costs.\n\n\n\nEstablishing community-wide conventions for data standards and workflow best practices is crucial for developing robust cyberinfrastructure. However, a balance must be struck between standardization and flexibility to accommodate the diverse needs of ecological forecasting. Integrating and harmonizing heterogeneous data from diverse sources is a significant barrier, particularly for biological and ecological data which are difficult to standardize. Therefore, the focus should be on common concepts and prioritizing standard outputs rather than inputs, which allows for direct comparison of outcomes.\nThe development of standards should be fostered through communities of practice since grassroots involvement will lead to greater adoption and widespread acceptance. Where available, existing conventions should be borrowed, and if no standards exist, then a project is encouraged to create them. To incentivize the establishment and adoption of data standards and best practices, they can be required by funding agencies and recognized by communities as with forecasting challenges. Further support should be provided by collating catalogs of existing models, data, and tools, and by investing in open-source technologies.\n\n\n\nCyberinfrastructure for ecological forecasting requires people with diverse skills and expertise to ensure effective development, implementation, and maintenance of the system. At the research stage, ecological forecasters are often domain scientists and data scientists who often struggle to operationalize a model into a workflow because of the steep learning curve to the skills and expertise needed. In addition to scientific knowledge, ecological forecasting requires technical skills in software development, continuous deployment, cloud architecture, data management, visualization, and project management. Collaboration and effective communication is needed among people with these various backgrounds in order to advance ecological forecasting. However, there is a lack of trained individuals accessible to the ecological forecasting community who can fill those roles.\nMultiple strategies should be employed to build the human infrastructure needed for ecological forecasting. These include training and workforce development for new professionals to fill various roles as well as skill-building for inexperienced workers. This will enable them to work towards operationalizing models and more effectively communicate and collaborate with other technical professionals.\n\n\n\nWhen designing an ecological forecasting model and supporting cyberinfrastructure, it is essential to meaningfully engage with stakeholders early on and continuously throughout the research and operationalization process. Ecological forecasting models should be designed to inform specific decisions to ensure their relevance and usefulness. This design includes their visualization to ensure that the information being transmitted is intuitive and accessible, providing stakeholders with clear and actionable insights.\nHowever, effective stakeholder engagement takes time to build relationships and trust, and high-quality engagement is particularly challenging when working with marginalized and under-resourced communities. Embedding design justice principles into the development process can center the voices and needs of these communities during the creation of ecological forecasting tools. This approach advocates for equitable participation and the inclusion of diverse perspectives which helps distribute the benefits of ecological forecasting equitably and addresses the unique challenges faced by marginalized groups. For ecological forecasting cyberinfrastructure, specific concerns include the relevance and accessibility of products and the use of data derived from marginalized communities. In those latter cases, following CARE (Collective Benefit, Authority to Control, Responsibility, and Ethics) principles can further help avoid potential conflicts and ensure ethical practices.\n\n\n\nScience culture and institutions incentivize novelty and innovation, while the operationalization of ecological forecasts with cyberinfrastructure requires stability, reliability, and continuity. Furthermore, there are tensions between what is considered research quality and production quality which hinders the translation of models into operation-ready workflows. These barriers are exacerbated by limited scope and duration of grant funding which is typically inadequate for establishing and maintaining cyberinfrastructure.\nOrganizational inertia is another obstacle to ecological forecasting implementation since workers are habituated to rely on particular funding sources and use familiar technologies and workflows which are not well-suited for sustained cyberinfrastructure. These ruts may also make workers resistant to using established conventions and best practices in favor of their own or those used by their organization. Meanwhile, different agencies and organizations have their own missions and security requirements which may make steps towards interoperability challenging.\nCross-agency collaboration and implementation of sustained cyberinfrastructure is a sure path towards the advancement of ecological forecasting, but it will require overcoming cultural and institutional barriers. Therefore, it is imperative for grassroots communities in conjunction with agency champions to organize and advocate for necessary changes.\n\n\n\nThe workshop was conceived on the premise that ecological forecasting cyberinfrastructure lacks widely accepted design principles. However, participants largely agreed with the best practices presented, which are consistent with the existing literature. Despite this consensus, barriers to adoption persist, primarily due to human factors, organizational culture, and limited institutional resources. To overcome these obstacles, we recommend the following:\n\nDevelop compelling communication materials in coordination with scientific societies including:\n\nWhite papers that explain the need for ecological forecasting and cyberinfrastructure\nCase studies that showcase the success of ecological forecasting\nFlagship projects that could have substantial impact and visibility\n\nFind and empower champions at multiple levels within agencies and equip them with communication materials\nBuild communities of practice:\n\nParticipate in their workshops and conferences to promote cyberinfrastructure best practices\nProvide them with tools, training, and platforms to foster collaborations\n\nExpand the workforce and bridge expertise by collaborating with academic partners to modernize curricula, develop core competencies, and create professional development opportunities\nAlign with agency missions and priorities to gain traction in a resource-constrained environment\n\nReframe ecological forecasting in terms of agency missions and societal priorities such as economic development, public health, food and water security, hazard resilience, and environmental justice.\nCapitalize on strategic opportunities such as high-profile initiatives, administration transitions, and budget cycles to promote ecological forecasting\n\nAdvocate for ecological forecasting cyberinfrastructure in coordination with scientific societies, stakeholder groups, and boundary organizations to effectively translate needs, priorities, and opportunities."
  },
  {
    "objectID": "workshopsummary/brief.html#a-workshop-for-cyberinfrastructure-design-principles",
    "href": "workshopsummary/brief.html#a-workshop-for-cyberinfrastructure-design-principles",
    "title": " EFI-CI Briefing Paper",
    "section": "",
    "text": "Cyberinfrastructure can facilitate our ability to create, improve, and learn from forecasts, but seemingly there is a lack of widely accepted cyberinfrastructure design principles which is a major obstacle for researchers and organizations seeking to engage in ecological forecasting. In an effort to address these obstacles, a workshop was convened by EFI and the Northeastern Regional Association for Coastal Ocean Observing Systems (NERACOOS) to: 1. Collate common cyberinfrastructure practices currently used 2. Identify cyberinfrastructure needs and gaps 3. Propose cyberinfrastructure designs for various forecasting problems\nThe workshop participants included a diverse mix of participants from various sectors including NGOs, private industry, academia, and federal agencies.\nThrough presentations, panels, and breakout sessions, participants discussed workflows, best practices, and the implementation of cyberinfrastructure across agencies. Although there were technical presentations, the makeup of participants influenced the scope of the topics covered and contributed to the majority of discussions focusing on higher level concepts and general design rather than the technical aspects of cyberinfrastructure. Often the participants’ recommendations reflected those that are in the literature, such as the FAIR principles which stipulate that data should be findable, accessible, interoperable, and reusable. Otherwise, their varied experiences and perspectives highlighted the many challenges which hinder adoption of best practices and advancement of ecological forecasting. Here we report on some of the major themes from the workshop and identify areas for advancing the implementation of cyberinfrastructure to support ecological forecasting."
  },
  {
    "objectID": "workshopsummary/brief.html#cyberinfrastructure-and-cloud-based-architecture",
    "href": "workshopsummary/brief.html#cyberinfrastructure-and-cloud-based-architecture",
    "title": " EFI-CI Briefing Paper",
    "section": "",
    "text": "Cyberinfrastructure refers to the integrated suite of hardware, software, data, and human resources designed to support data analysis and information processing. The design of cyberinfrastructure for ecological forecasting can take many different forms and the sequence of processes within that infrastructure constitutes the workflow. Cyberinfrastructure best practices include concepts like data standards and modularity which enable the workflow to be automated, flexible, and scalable. These workflow best practices are also aspects of cloud-based architecture which involves designing systems specifically to leverage cloud services and capabilities. However, cyberinfrastructure can adopt cloud-based architecture principles without using vendor cloud services. Doing so takes advantage of the flexible, scalable, efficient design while enabling local control and the use of cost-effective infrastructure like on-premises high-performance-computing systems.\nThe rapid and inevitable shift to cloud computing is upending traditional IT architectures, procurement models, and budget structures. Organizations risk cost inflation and loss of leverage to commercial providers when locking into cloud vendor services. Utilizing cloud-based architecture while minimizing reliance on services is a solution to some of the challenges and enables adoption of cyberinfrastructure best practices. Another strategy is to coordinate across agencies and other organizations to reach collective or at least transparent agreements on service requirements and costs."
  },
  {
    "objectID": "workshopsummary/brief.html#community-standards-best-practices-and-flexibility",
    "href": "workshopsummary/brief.html#community-standards-best-practices-and-flexibility",
    "title": " EFI-CI Briefing Paper",
    "section": "",
    "text": "Establishing community-wide conventions for data standards and workflow best practices is crucial for developing robust cyberinfrastructure. However, a balance must be struck between standardization and flexibility to accommodate the diverse needs of ecological forecasting. Integrating and harmonizing heterogeneous data from diverse sources is a significant barrier, particularly for biological and ecological data which are difficult to standardize. Therefore, the focus should be on common concepts and prioritizing standard outputs rather than inputs, which allows for direct comparison of outcomes.\nThe development of standards should be fostered through communities of practice since grassroots involvement will lead to greater adoption and widespread acceptance. Where available, existing conventions should be borrowed, and if no standards exist, then a project is encouraged to create them. To incentivize the establishment and adoption of data standards and best practices, they can be required by funding agencies and recognized by communities as with forecasting challenges. Further support should be provided by collating catalogs of existing models, data, and tools, and by investing in open-source technologies."
  },
  {
    "objectID": "workshopsummary/brief.html#human-capital-collaboration-and-communication",
    "href": "workshopsummary/brief.html#human-capital-collaboration-and-communication",
    "title": " EFI-CI Briefing Paper",
    "section": "",
    "text": "Cyberinfrastructure for ecological forecasting requires people with diverse skills and expertise to ensure effective development, implementation, and maintenance of the system. At the research stage, ecological forecasters are often domain scientists and data scientists who often struggle to operationalize a model into a workflow because of the steep learning curve to the skills and expertise needed. In addition to scientific knowledge, ecological forecasting requires technical skills in software development, continuous deployment, cloud architecture, data management, visualization, and project management. Collaboration and effective communication is needed among people with these various backgrounds in order to advance ecological forecasting. However, there is a lack of trained individuals accessible to the ecological forecasting community who can fill those roles.\nMultiple strategies should be employed to build the human infrastructure needed for ecological forecasting. These include training and workforce development for new professionals to fill various roles as well as skill-building for inexperienced workers. This will enable them to work towards operationalizing models and more effectively communicate and collaborate with other technical professionals."
  },
  {
    "objectID": "workshopsummary/brief.html#design-justice-principles-and-stakeholder-engagement",
    "href": "workshopsummary/brief.html#design-justice-principles-and-stakeholder-engagement",
    "title": " EFI-CI Briefing Paper",
    "section": "",
    "text": "When designing an ecological forecasting model and supporting cyberinfrastructure, it is essential to meaningfully engage with stakeholders early on and continuously throughout the research and operationalization process. Ecological forecasting models should be designed to inform specific decisions to ensure their relevance and usefulness. This design includes their visualization to ensure that the information being transmitted is intuitive and accessible, providing stakeholders with clear and actionable insights.\nHowever, effective stakeholder engagement takes time to build relationships and trust, and high-quality engagement is particularly challenging when working with marginalized and under-resourced communities. Embedding design justice principles into the development process can center the voices and needs of these communities during the creation of ecological forecasting tools. This approach advocates for equitable participation and the inclusion of diverse perspectives which helps distribute the benefits of ecological forecasting equitably and addresses the unique challenges faced by marginalized groups. For ecological forecasting cyberinfrastructure, specific concerns include the relevance and accessibility of products and the use of data derived from marginalized communities. In those latter cases, following CARE (Collective Benefit, Authority to Control, Responsibility, and Ethics) principles can further help avoid potential conflicts and ensure ethical practices."
  },
  {
    "objectID": "workshopsummary/brief.html#culture-institutions-and-community",
    "href": "workshopsummary/brief.html#culture-institutions-and-community",
    "title": " EFI-CI Briefing Paper",
    "section": "",
    "text": "Science culture and institutions incentivize novelty and innovation, while the operationalization of ecological forecasts with cyberinfrastructure requires stability, reliability, and continuity. Furthermore, there are tensions between what is considered research quality and production quality which hinders the translation of models into operation-ready workflows. These barriers are exacerbated by limited scope and duration of grant funding which is typically inadequate for establishing and maintaining cyberinfrastructure.\nOrganizational inertia is another obstacle to ecological forecasting implementation since workers are habituated to rely on particular funding sources and use familiar technologies and workflows which are not well-suited for sustained cyberinfrastructure. These ruts may also make workers resistant to using established conventions and best practices in favor of their own or those used by their organization. Meanwhile, different agencies and organizations have their own missions and security requirements which may make steps towards interoperability challenging.\nCross-agency collaboration and implementation of sustained cyberinfrastructure is a sure path towards the advancement of ecological forecasting, but it will require overcoming cultural and institutional barriers. Therefore, it is imperative for grassroots communities in conjunction with agency champions to organize and advocate for necessary changes."
  },
  {
    "objectID": "workshopsummary/brief.html#conclusion-and-recommendations",
    "href": "workshopsummary/brief.html#conclusion-and-recommendations",
    "title": " EFI-CI Briefing Paper",
    "section": "",
    "text": "The workshop was conceived on the premise that ecological forecasting cyberinfrastructure lacks widely accepted design principles. However, participants largely agreed with the best practices presented, which are consistent with the existing literature. Despite this consensus, barriers to adoption persist, primarily due to human factors, organizational culture, and limited institutional resources. To overcome these obstacles, we recommend the following:\n\nDevelop compelling communication materials in coordination with scientific societies including:\n\nWhite papers that explain the need for ecological forecasting and cyberinfrastructure\nCase studies that showcase the success of ecological forecasting\nFlagship projects that could have substantial impact and visibility\n\nFind and empower champions at multiple levels within agencies and equip them with communication materials\nBuild communities of practice:\n\nParticipate in their workshops and conferences to promote cyberinfrastructure best practices\nProvide them with tools, training, and platforms to foster collaborations\n\nExpand the workforce and bridge expertise by collaborating with academic partners to modernize curricula, develop core competencies, and create professional development opportunities\nAlign with agency missions and priorities to gain traction in a resource-constrained environment\n\nReframe ecological forecasting in terms of agency missions and societal priorities such as economic development, public health, food and water security, hazard resilience, and environmental justice.\nCapitalize on strategic opportunities such as high-profile initiatives, administration transitions, and budget cycles to promote ecological forecasting\n\nAdvocate for ecological forecasting cyberinfrastructure in coordination with scientific societies, stakeholder groups, and boundary organizations to effectively translate needs, priorities, and opportunities."
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Reference",
    "section": "",
    "text": "Acronyms and Definitions\nParticipants"
  },
  {
    "objectID": "reference/index.html#reference-documents",
    "href": "reference/index.html#reference-documents",
    "title": "Reference",
    "section": "",
    "text": "Acronyms and Definitions\nParticipants"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cyberinfrastructure for Efficient Ecological Forecasting",
    "section": "",
    "text": "The lack of widely accepted cyberinfrastructure (CI) design principles poses a major obstacle for researchers and organizations seeking to engage in ecological forecasting. In an effort to address these obstacles, a workshop convened forecasting researchers and CI experts from government, academia, industry, and NGOs to:\n\nCollate common CI practices currently used\n\nIdentify CI needs and gaps\n\nPropose CI designs for various forecasting problems\n\n\n\nAn objective of the workshop was to create an open-access version-controlled online document. This document was envisioned as a community-developed handbook of CI design principles and recommended practices accessible to the workshop participants and the broader Ecological Forecasting Initiative (EFI) community. The living document is to function as a comprehensive CI guide for both novice and experienced forecasters aligned with community-developed forecasting standards (Dietze et al. 2023)."
  },
  {
    "objectID": "index.html#workshop-outcomes",
    "href": "index.html#workshop-outcomes",
    "title": "Cyberinfrastructure for Efficient Ecological Forecasting",
    "section": "",
    "text": "An objective of the workshop was to create an open-access version-controlled online document. This document was envisioned as a community-developed handbook of CI design principles and recommended practices accessible to the workshop participants and the broader Ecological Forecasting Initiative (EFI) community. The living document is to function as a comprehensive CI guide for both novice and experienced forecasters aligned with community-developed forecasting standards (Dietze et al. 2023)."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Cyberinfrastructure for Efficient Ecological Forecasting",
    "section": "Getting Started",
    "text": "Getting Started\n\nPrerequisites\nBefore you start, you will need:\n\nA GitHub account. You can sign up for one here.\nGit installed on your computer. Follow the instructions here to install Git.\nBasic knowledge of Git and GitHub. If you’re new to these, we recommend this tutorial.\n\n\n\nInstallation\n\nFork the repository\nClick the “Fork” button at the top right of the efi-ci-workshop-2024 github repository to create a copy of this repository under your GitHub account.\nClone your fork\ngit clone https://github.com/YOUR-USERNAME/efi-ci-workshop-2024.git\nNavigate to the repository directory\n cd efi-ci-workshop-2024\nCreate a new branch\ngit checkout -b your-branch-name"
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "Cyberinfrastructure for Efficient Ecological Forecasting",
    "section": "Contributing",
    "text": "Contributing\n\nFind an issue or task\nCheck the Issues tab to find tasks that need to be completed or discussions that need your input. You can also create new issues or suggest improvements.\nWork on your task\nOnce you’ve selected an issue or task, start working on it in your forked repository. Make sure to keep your changes focused and relevant to the task at hand.\nPreview the website\n(Optional) To preview your changes locally, you’ll need a Quarto installation.\nThere are several ways to work with Quarto. The Quarto documentation provides detailed instructions on how to install it for RStudio, Jupyter, VS Code, and other tools. Once Quarto is installed, you can easily preview your content using your preferred tool:\n\n\nRStudioShell / Text EditorVS Code\n\n\nOpen the RStudio project file in the repo. Now you can render and preview the site with quarto::quarto_preview(). RStudio will pop up a web browser to preview the site. As you edit files, you can click the “Render on Save” checkbox, and the website will be updated whenever you save a change to them.\n\n\nIf you’re working with lower-level tools like bash and vim, you can render the site at the shell and start up a preview server with\nquarto render\nquarto preview\nThe quarto preview command should open a web page to the correct location. If it does not, you can see the URL to go to in the command’s output.\n\n\nWithin VS Code install the Quarto extension.\nTo render the site:\nCtrl+Shift+K on PC or Cmd+Shift+K on mac. Althernatively, there is a ‘Quarto:Preview’ button () in the upper right-hand corner that will build the page.\nTo execute a single code cell within a qmd:\nCtrl+Shift+Enter on PC or Cmd+Shift+Enter on mac.\nTo close a preview session press Ctrl+C on PC or Cmd+C on a mac.\n\n\n\n\nCommit your changes\ngit add .\ngit commit -m \"Brief description of your changes\"\nPush your changes to your fork\ngit push origin your-branch-name\nCreate a Pull Request\nGo to your forked repository on GitHub, and you should see a “Compare & pull request” button. Click it and follow the instructions to submit your pull request.\nGet a review\nYou can tag someone in particular to review the content you’re proposing to add; if you don’t tag anyone in particular, one of the repository maintainers will review your PR.\n\n\nCitations\nCiting sources in Quarto works just like using BibTeX in a research paper. First, add your references to the references.bibtex file. Then, you can cite them directly in the page text. For example, to cite the Ecological Forecasting Standards, you would write [@dietze2023community] which renders as (Dietze et al. 2023). For more information, see the quarto help page on citations and footnotes."
  },
  {
    "objectID": "index.html#current-documents",
    "href": "index.html#current-documents",
    "title": "Cyberinfrastructure for Efficient Ecological Forecasting",
    "section": "Current documents",
    "text": "Current documents\n\nWorkshop Summary \nReference Documents"
  },
  {
    "objectID": "index.html#organizers-and-funders",
    "href": "index.html#organizers-and-funders",
    "title": "Cyberinfrastructure for Efficient Ecological Forecasting",
    "section": "Organizers and Funders",
    "text": "Organizers and Funders\nThe workshop was co-hosted by EFI and the Northeastern Regional Association for Coastal Ocean Observing Systems (NERACOOS) in Portsmouth, New Hampshire. It was made possible through support from the National Oceanic and Atmospheric Administration/US IOOS, the National Aeronautics and Space Administration, the Northeastern Regional Association of Coastal Ocean Observing Systems, the Ecological Forecasting Initiative, and the U.S. Geological Survey.\nOrganizing Committee: Jake Zwart (USGS), Hassan Moustahfid (NOAA), Chris Brown (University of Maryland), Jessica Burnett (NASA), Jake Kritzer (NERACOOS), Rob Cardeiro (NERACOOS), Cameron Thompson (NERACOOS), Emily Silva (NERACOOS), Caitlin Shanahan (NERACOOS), Jody Peters (University of Notre Dame), Mike Dietze (Boston University)"
  },
  {
    "objectID": "reference/EFI_CI_reference.html",
    "href": "reference/EFI_CI_reference.html",
    "title": " Acronyms and Definitions",
    "section": "",
    "text": "ALMA: Assistance for Land-surface Modelling activities\nAPIs: Application Programming Interfaces\nCI: Cyberinfrastructure\nCSV: Comma-separated values\nDMAC: Data Management and Cyberinfrastructure\nEFI: Ecological Forecasting Initiative\nHAB: Harmful Algal Bloom\nIAAs: Interagency Agreements\nIFCB: Imaging FlowCytobot\nIMPACT: Inter-agency Implementation and Advanced Concepts Team\nIOOS: Integrated Ocean Observing System\nIoT: Internet of Things\nLTER: Long Term Ecological Research\nMIPs: Model Intercomparison Projects\nNASA: National Aeronautics and Space Administration\nNCCOS: National Centers for Coastal Ocean Science\nNEON: National Ecological Observatory Network\nNERACOOS: Northeastern Regional Association for Coastal Ocean Observing Systems\nNetCDF: Network Common Data Form\nNGOs: Non-Governmental Organizations\nNHABON: National Harmful Algal Bloom Observing Network\nNOAA: National Oceanic and Atmospheric Administration\nOBIS: Ocean Biodiversity Information System\nPEcAn: Predictive Ecosystem Analyzer\nS3: Simple Storage Service\nSCCOOS: Southern California Coastal Ocean Observing System\nSTAC: SpatioTemporal Asset Catalog\nUSGS: United States Geological Survey"
  },
  {
    "objectID": "reference/EFI_CI_reference.html#acronyms-and-abbreviations",
    "href": "reference/EFI_CI_reference.html#acronyms-and-abbreviations",
    "title": " Acronyms and Definitions",
    "section": "",
    "text": "ALMA: Assistance for Land-surface Modelling activities\nAPIs: Application Programming Interfaces\nCI: Cyberinfrastructure\nCSV: Comma-separated values\nDMAC: Data Management and Cyberinfrastructure\nEFI: Ecological Forecasting Initiative\nHAB: Harmful Algal Bloom\nIAAs: Interagency Agreements\nIFCB: Imaging FlowCytobot\nIMPACT: Inter-agency Implementation and Advanced Concepts Team\nIOOS: Integrated Ocean Observing System\nIoT: Internet of Things\nLTER: Long Term Ecological Research\nMIPs: Model Intercomparison Projects\nNASA: National Aeronautics and Space Administration\nNCCOS: National Centers for Coastal Ocean Science\nNEON: National Ecological Observatory Network\nNERACOOS: Northeastern Regional Association for Coastal Ocean Observing Systems\nNetCDF: Network Common Data Form\nNGOs: Non-Governmental Organizations\nNHABON: National Harmful Algal Bloom Observing Network\nNOAA: National Oceanic and Atmospheric Administration\nOBIS: Ocean Biodiversity Information System\nPEcAn: Predictive Ecosystem Analyzer\nS3: Simple Storage Service\nSCCOOS: Southern California Coastal Ocean Observing System\nSTAC: SpatioTemporal Asset Catalog\nUSGS: United States Geological Survey"
  },
  {
    "objectID": "reference/EFI_CI_reference.html#ecological-forecasting-cyberinfrastructure-terms",
    "href": "reference/EFI_CI_reference.html#ecological-forecasting-cyberinfrastructure-terms",
    "title": " Acronyms and Definitions",
    "section": "Ecological Forecasting Cyberinfrastructure Terms",
    "text": "Ecological Forecasting Cyberinfrastructure Terms\n\nDesign Justice Principles\n(Retrieved from Design Justice Network)\n\nWe use design to sustain, heal, and empower our communities as well as to seek liberation from exploitative and oppressive systems.\nWe center the voices of those who are directly impacted by the outcomes of the design process.\nWe prioritize design’s impact on the community over the intentions of the designer.\nWe view change as emergent from an accountable, accessible, and collaborative process rather than as a point at the end of a process.\nWe see the role of the designer as a facilitator rather than an expert.\nWe believe that everyone is an expert based on their own lived experiences and that we all have unique and brilliant contributions to bring to a design process.\nWe share design knowledge and tools with our communities.\nWe work towards sustainable, community-led, and community-controlled outcomes.\nWe work towards non-exploitative solutions that reconnect us to the earth and to each other.\nBefore seeking new design solutions, we look for what is already working at the community level.\n\n\n\nCARE Principles\nFrom (Carroll et al. 2020)\n\nCollective Benefit\n\nC1: For inclusive development and innovation\nC2: For improved governance and citizen engagement\nC3: For equitable outcomes\n\nAuthority to Control\n\nA1: Recognizing rights and interests\nA2: Data for governance\nA3: Governance of data\n\nResponsibility\n\nR1: For positive relationships\nR2: For expanding capability and capacity\nR3: For Indigenous languages and worldviews\n\nEthics\n\nE1: For minimizing harm and maximizing benefit\nE2: For justice\nE3: For future use\n\n\n\n\nFAIR Principles\nFrom (Wilkinson et al. 2016)\n\nTo be Findable:\n\nF1. (meta)data are assigned a globally unique and persistent identifier\nF2. data are described with rich metadata (defined by R1 below)\nF3. metadata clearly and explicitly include the identifier of the data it describes\nF4. (meta)data are registered or indexed in a searchable resource\n\nTo be Accessible:\n\nA1. (meta)data are retrievable by their identifier using a standardized communications protocol\n\nA1.1 the protocol is open, free, and universally implementable\nA1.2 the protocol allows for an authentication and authorization procedure where necessary\n\nA2. metadata are accessible even when the data are no longer available\n\nTo be Interoperable:\n\nI1. (meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation\nI2. (meta)data use vocabularies that follow FAIR principles\nI3. (meta)data include qualified references to other (meta)data\n\nTo be Reusable:\n\nR1. meta(data) are richly described with a plurality of accurate and relevant attributes\n\nR1.1. (meta)data are released with a clear and accessible data usage license\nR1.2. (meta)data are associated with detailed provenance\nR1.3. (meta)data meet domain-relevant community standards\n\n\n\n\n\nAdapted Forecasting and Cyberinfrastructure Terms from (Fer et al. 2021)\n\nAbstraction: The process of focusing on the design of the IT system architecture and how components relate to one another.\nAccessibility: Availability of software and data in a public location with complete metadata and the protocols to use, install, implement, and employ them shared.\nAlgorithms: A set of rules designed to solve a computational problem.\nApplication Programming Interfaces (APIs): Tools for programmatically interacting with data online.\nAssistance for Land-surface Modeling activities (ALMA): A data convention that ensures consistency in naming, unit, and sign standards for variable exchange in model-data activities.\nBenchmarking: Assessing a model’s skill based on a priori performance expectations.\nComma-separated values (CSV): Text files using commas to separate values.\nCyberinfrastructure: IT systems with components for data storage and advanced informatics for simulating natural phenomena and scientific interpretation.\nData assimilation: Combining model predictions with observations to update system understanding.\nDatabase: Electronic systems that store and organize data and metadata.\nInternet of Things (IoT): Network of interconnected sensors and smart devices for automated environmental monitoring.\nInteroperability: The ability of software to work with other products.\nMetadata: Descriptive data providing documentation about other data or software.\nModel Intercomparison Projects (MIPs): Multi-institutional efforts for model evaluation and benchmarking.\nNetwork Common Data Form (NetCDF): A file format for storing array-oriented scientific data and metadata.\nOntologies: Standardized collections of terms.\nOpen file format: A file format without restrictions on use by any software.\nProvenance: Historical information of all analysis steps and components.\nRepository: Online storage for hosting software and code with related documentation.\nReusability: The versatility of data and software in different settings.\nScheduler: Software for managing scientific workflows periodically.\nSoftware container: An application package with dependencies for code execution.\nWorkflow: Computational tasks executed in sequence with data flow.\nVirtual machines: Software providing basic OS functionality in a contained environment.\n\n\n\nAdapted Forecasting and Cyberinfrastructure Terms from (Hendry 2023)\n\nHypothesis: An expectation on system workings for testable predictions.\nPrediction: Formal assertion about a state or outcome before it is known.\nExpectation: A weaker form of prediction with higher uncertainty.\nQuestion: Inquiry about system information for generating predictions.\nPredictable: A precise and accurate state or outcome given adequate system knowledge.\nProphecy (prediction as …): A formal prediction about the future state of a system.\nDiagnosis (prediction as …): A formal prediction about the current state of a system.\nHistory (prediction as …): A formal prediction about the past state of a system.\nRepeatability (prediction as …): Phenomena that are repeatable could also be predictable with sufficient knowledge.\nFate (prediction as …): When evidence suggests an outcome is inevitable.\nParallel or convergent (in the sense of evolution): Cases where evolution generates similar outcomes under similar conditions.\nForecasting: Using past or present data to predict the future.\nHindcasting: Using current or past data to predict another past state.\nUncertainty: The level of confidence in a prediction or outcome test."
  },
  {
    "objectID": "reference/EFI_CI_reference.html#other-technical-terminology",
    "href": "reference/EFI_CI_reference.html#other-technical-terminology",
    "title": " Acronyms and Definitions",
    "section": "Other Technical Terminology",
    "text": "Other Technical Terminology\n\nCloud-native architecture: A way of designing applications specifically to run on cloud platforms, making them easy to scale, flexible, and built from smaller, interchangeable parts.\nContainerization: A method of packaging software so it can run consistently across different computing environments.\nDocker: A popular platform for containerization that simplifies creating, deploying, and running applications by using containers.\nEvent-driven workflow: A system where actions are triggered by specific events like a sensor sending data, often used in cloud computing to automate processes.\nFairweather Report: A 2003 report by the National Academies Press on improving the provision of civilian weather and climate services.\nI/O (Input/Output): Communication between a computer system and the outside world, involving receiving (input) and sending (output) data.\nKerchunk: A software tool that helps organize and store data efficiently in the cloud.\nLoosely-coupled interfaces: Connections between software systems that are designed to interact with each other with minimal dependency, making it easier to update or change parts without affecting the whole system.\nModular architecture: A design approach that builds a system from separate, interchangeable parts, making it easier to update and maintain.\nObject storage: A method of storing data in the cloud where each piece of data is stored as a distinct unit or “object” along with its associated metadata.\nOpenShift: A commercial cloud-based platform by Red Hat that helps developers build and manage containerized applications.\nProvenance tracking: Keeping detailed records of where data comes from and all the steps it goes through, ensuring data integrity and traceability.\nReproducible compute environments: Setups for running software that can be exactly replicated, ensuring that the same code always produces the same results, often using container technologies like Docker.\nServerless computing: A cloud service model where the cloud provider manages the servers, allowing developers to run code without worrying about server maintenance.\nSTAC (SpatioTemporal Asset Catalog): A standard that helps organize and share spatiotemporal data.\nStack Catalog: A specification for organizing and searching metadata about spatiotemporal data, making it easier to find and share such data.\nThredds: A server that makes it easy to access and share scientific data using common standards.\nZarr: A format for efficiently storing large multi-dimensional arrays of data, often used in scientific research."
  },
  {
    "objectID": "reference/participants.html",
    "href": "reference/participants.html",
    "title": " Participants",
    "section": "",
    "text": "Alexandra Kirk - NASA IMPACT\nBruce Wilson - Oak Ridge National Laboratory (ORNL) Distributed Active Archive Center\nCaitlin Shanahan - NERACOOS\nCameron Thompson - NERACOOS\nCarl Boettiger - University of California Berkeley\nChris Brown - University of Maryland\nChris Tate - Red Hat\nClarissa Anderson - University of California San Diego and SCCOOS\nDavid Scheurer - NOAA Ocean Service\nDavid Watkins - USGS\nEmily Silva - NERACOOS\nHassan Moustahfid - NOAA\nIstem Fer - Finnish Meteorological Institute\nJake Kritzer - NERACOOS\nJake Zwart - USGS\nJessica Burnett - NASA\nJody Peters - University of Notre Dame\nKelly Knee - RPS Ocean Science\nMarie Colton - Hydros LLC\nMelissa Kenney - University of Minnesota Institute on the Environment\nMike Dietze - Boston University\nQuinn Thomas - Virginia Tech\nRenato Figueiredo - University of Florida\nRob Cardeiro - NERACOOS\nSean Dorr - University of Minnesota Twin Cities\nTyson Swetnam - University of Arizona"
  },
  {
    "objectID": "reference/participants.html#named-participants-and-affiliations",
    "href": "reference/participants.html#named-participants-and-affiliations",
    "title": " Participants",
    "section": "",
    "text": "Alexandra Kirk - NASA IMPACT\nBruce Wilson - Oak Ridge National Laboratory (ORNL) Distributed Active Archive Center\nCaitlin Shanahan - NERACOOS\nCameron Thompson - NERACOOS\nCarl Boettiger - University of California Berkeley\nChris Brown - University of Maryland\nChris Tate - Red Hat\nClarissa Anderson - University of California San Diego and SCCOOS\nDavid Scheurer - NOAA Ocean Service\nDavid Watkins - USGS\nEmily Silva - NERACOOS\nHassan Moustahfid - NOAA\nIstem Fer - Finnish Meteorological Institute\nJake Kritzer - NERACOOS\nJake Zwart - USGS\nJessica Burnett - NASA\nJody Peters - University of Notre Dame\nKelly Knee - RPS Ocean Science\nMarie Colton - Hydros LLC\nMelissa Kenney - University of Minnesota Institute on the Environment\nMike Dietze - Boston University\nQuinn Thomas - Virginia Tech\nRenato Figueiredo - University of Florida\nRob Cardeiro - NERACOOS\nSean Dorr - University of Minnesota Twin Cities\nTyson Swetnam - University of Arizona"
  },
  {
    "objectID": "reference/participants.html#participant-impressions",
    "href": "reference/participants.html#participant-impressions",
    "title": " Participants",
    "section": "Participant Impressions",
    "text": "Participant Impressions\nThe workshop participants included a diverse mix of 41 participants from various sectors. Federal agencies were well-represented with 19 participants from 6 different agencies including USGS, NOAA, and NASA. Academia contributed 12 participants from 11 different institutions with international representation from the Finnish Meteorological Institute. The private sector added 5 participants, while NGOs including IOOS regional associations represented the remainder.\nAccording to an exit survey of 28 participants prior to the workshop, the majority of attendees were slightly or moderately knowledgeable of ecological forecasting CI. Around 20% were very knowledgeable, and 7% were not at all knowledgeable. This makeup of participants influenced the scope of the topics covered, focusing more on higher level concepts and general design rather than the technical aspects of cyber infrastructure. Overall, the workshop was well received. It met participants’ expectations, with the majority being ‘extremely satisfied’, although the lack of technical content was noted by several survey respondents.\nReported knowledge gains from the workshop were significant. Participants increased their familiarity with the EFI initiative, NERACOOS, and ecological forecasting cyberinfrastructure in general. There was a strong gain in knowledge about the forecasting cyberinfrastructure of other organizations, increasing from 0% and 11% to 14% and 71% (very knowledgeable and moderately knowledgeable respectively). The strong satisfaction of participants with the workshop was underscored by strong agreement that the workshop facilitated effective collaboration, increased community engagement, and was considered a valuable use of time aligning well with personal goals. Moreover, interactions with workshop organizers and the efficacy of communications were particularly praised. Participants valued the chance to meet peers, learn from diverse CI use cases, and engage in discussions that spanned across multiple perspectives including those focusing on design justice principles. Recommendations for future workshops emphasized a desire for more hands-on experiences with cyberinfrastructure tools, deeper technical discussions, and enhanced skill-building sessions."
  },
  {
    "objectID": "workshopsummary/index.html",
    "href": "workshopsummary/index.html",
    "title": "Workshop Summary",
    "section": "",
    "text": "The workshop’s agenda was crafted to cover essential CI design topics recommended by the organizing committee for inclusion in the handbook and to gather valuable input from attendees. Throughout the workshop, we documented the presentations, breakout sessions, and plenary discussions meticulously through detailed notes and audio recording transcripts. These materials were subsequently reviewed and refined to ensure clarity and accuracy in preparation for summarization.\nEach workshop session was summarized with the assistance of a Large Language Model AI specifically Claude 3 Opus. We provided the AI with the workshop’s annotated agenda, transcripts of audio recordings, presentation slides, and notes along with specific instructions to generate detailed summaries. These instructions were iteratively fine-tuned to ensure the summaries met our standards. Finally, we carefully reviewed the summaries to ensure they accurately reflected the workshop’s discussions. Special attention was given to common themes emerging from the breakout sessions which required deeper interpretation and analysis. The collation of those notes can be found in the following document which the community and workshop participants are encouraged to comment on.\n\n\n\nA 1500-word briefing paper has been prepared in lieu of the initially planned community-developed handbook of CI design principles. After collating the workshop materials and reviewing the workshop exit survey, it was apparent that the workshop discussions were held at a higher level than necessary to achieve the initial goal. At this higher non-technical level of discussion, there were existing design principles that participants agreed with, but there are nonetheless obstacles to implementation.\nThe briefing paper outlines the necessity of cyberinfrastructure (CI) and highlights key thematic obstacles to implementation as identified in the workshop. Additionally, it includes recommendations derived from these themes. The target audience includes potential advocates in agencies, scientific societies, stakeholder groups, and boundary organizations who may not possess technical expertise but can recognize the need for CI. The broader EFI community and workshop participants are encouraged to comment on this briefing paper."
  },
  {
    "objectID": "workshopsummary/index.html#workshop-summary-documents",
    "href": "workshopsummary/index.html#workshop-summary-documents",
    "title": "Workshop Summary",
    "section": "",
    "text": "The workshop’s agenda was crafted to cover essential CI design topics recommended by the organizing committee for inclusion in the handbook and to gather valuable input from attendees. Throughout the workshop, we documented the presentations, breakout sessions, and plenary discussions meticulously through detailed notes and audio recording transcripts. These materials were subsequently reviewed and refined to ensure clarity and accuracy in preparation for summarization.\nEach workshop session was summarized with the assistance of a Large Language Model AI specifically Claude 3 Opus. We provided the AI with the workshop’s annotated agenda, transcripts of audio recordings, presentation slides, and notes along with specific instructions to generate detailed summaries. These instructions were iteratively fine-tuned to ensure the summaries met our standards. Finally, we carefully reviewed the summaries to ensure they accurately reflected the workshop’s discussions. Special attention was given to common themes emerging from the breakout sessions which required deeper interpretation and analysis. The collation of those notes can be found in the following document which the community and workshop participants are encouraged to comment on.\n\n\n\nA 1500-word briefing paper has been prepared in lieu of the initially planned community-developed handbook of CI design principles. After collating the workshop materials and reviewing the workshop exit survey, it was apparent that the workshop discussions were held at a higher level than necessary to achieve the initial goal. At this higher non-technical level of discussion, there were existing design principles that participants agreed with, but there are nonetheless obstacles to implementation.\nThe briefing paper outlines the necessity of cyberinfrastructure (CI) and highlights key thematic obstacles to implementation as identified in the workshop. Additionally, it includes recommendations derived from these themes. The target audience includes potential advocates in agencies, scientific societies, stakeholder groups, and boundary organizations who may not possess technical expertise but can recognize the need for CI. The broader EFI community and workshop participants are encouraged to comment on this briefing paper."
  }
]